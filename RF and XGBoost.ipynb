{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections as c\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from numpy.random import normal,random,seed\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "#import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WEEK_OF_YEAR</th>\n",
       "      <th>CAMPAIGN</th>\n",
       "      <th>CAMPAIGN_TYPE</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Media_Cost</th>\n",
       "      <th>Page_Views</th>\n",
       "      <th>Time_On_Site_Total</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Visitor_Bounce</th>\n",
       "      <th>CPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>symptoms of asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>5.40</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>breathing with asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhaler names</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>breathing problems asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhaler otc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  WEEK_OF_YEAR  CAMPAIGN  CAMPAIGN_TYPE  \\\n",
       "0  5/21/2017 0:00            21        39              1   \n",
       "1  5/21/2017 0:00            21        39              1   \n",
       "2  5/21/2017 0:00            21        46              1   \n",
       "3  5/21/2017 0:00            21        40              1   \n",
       "4  5/21/2017 0:00            21        48              1   \n",
       "\n",
       "                     KEYWORD  NETWORK  POSITION  Clicks  Impressions  \\\n",
       "0         symptoms of asthma        1      2.08       3           51   \n",
       "1      breathing with asthma        1      2.00       1            4   \n",
       "2       asthma inhaler names        1      2.00       1            1   \n",
       "3  breathing problems asthma        1      1.00       1            1   \n",
       "4         asthma inhaler otc        1      1.70       1            3   \n",
       "\n",
       "   Media_Cost  Page_Views  Time_On_Site_Total  Visits  Visitor_Bounce   CPC  \n",
       "0        5.40           2                  13       2               1   1.8  \n",
       "1        3.71           1                   7       1               0  3.71  \n",
       "2        3.58           1                  42       1               0  3.58  \n",
       "3        3.24           1                   0       1               0  3.24  \n",
       "4        3.76           1                   4       1               0  3.76  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract most common words to build features - granular\n",
    "\n",
    "import numpy as np\n",
    "#categories: asthma Symptom treatment brand chemicals payment age cause\n",
    "\n",
    "\n",
    "# 1. symptom\n",
    "df['symptom'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('symptoms', case=False),\n",
    "        df['KEYWORD'].str.contains('signs', case=False),\n",
    "        df['KEYWORD'].str.contains('coughing'),\n",
    "        df['KEYWORD'].str.contains('breathing'),\n",
    "        df['KEYWORD'].str.contains('inflammation')\n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4, 5], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 2. asthma\n",
    "df['asthma'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('asthma', case=False),\n",
    "        df['KEYWORD'].str.contains('asma', case=False),\n",
    "        df['KEYWORD'].str.contains('asthmatic'),\n",
    "        df['KEYWORD'].str.contains('asthmas')\n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 3. treatment\n",
    "df['treatment'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('inhaler|inhalers', case=False),\n",
    "        df['KEYWORD'].str.contains('dosage|dosing|dose', case=False),\n",
    "        df['KEYWORD'].str.contains('80|40|mcg|mg'),\n",
    "        df['KEYWORD'].str.contains('treatment|treatments'),\n",
    "        df['KEYWORD'].str.contains('side|effects'),\n",
    "        df['KEYWORD'].str.contains('medications|medication|medicine|medicines', case=False),\n",
    "        df['KEYWORD'].str.contains('action', case=False),\n",
    "        df['KEYWORD'].str.contains('plan'),\n",
    "        df['KEYWORD'].str.contains('inhalation|aerosol'),\n",
    "        df['KEYWORD'].str.contains('over|otc', case=False),\n",
    "        df['KEYWORD'].str.contains('relief'),\n",
    "        df['KEYWORD'].str.contains('control|treat'),\n",
    "        df['KEYWORD'].str.contains('nasal'),\n",
    "        df['KEYWORD'].str.contains('use|used')\n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 4. brand\n",
    "df['brand'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('product1', case=False),\n",
    "        df['KEYWORD'].str.contains('competitor1', case=False),\n",
    "        df['KEYWORD'].str.contains('competitor5'),\n",
    "        df['KEYWORD'].str.contains('competitor7'),\n",
    "        df['KEYWORD'].str.contains('competitor6'),\n",
    "        df['KEYWORD'].str.contains('generic'),\n",
    "        df['KEYWORD'].str.contains('competitor8'),\n",
    "        df['KEYWORD'].str.contains('product1.com'),\n",
    "        df['KEYWORD'].str.contains('brands')    \n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4, 5, 6, 7, 8, 9], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    " \n",
    "# 5. chemical\n",
    "df['chemical'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('hfa', case=False),\n",
    "        df['KEYWORD'].str.contains('names', case=False),\n",
    "        df['KEYWORD'].str.contains('beclomethasone'),\n",
    "        df['KEYWORD'].str.contains('budesonide'),\n",
    "        df['KEYWORD'].str.contains('corticosteroid'),\n",
    "        df['KEYWORD'].str.contains('q|var|quvar')  \n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4, 5, 6], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 6. payment\n",
    "df['payment'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('coupon|coupons', case=False),\n",
    "        df['KEYWORD'].str.contains('copay', case=False),\n",
    "        df['KEYWORD'].str.contains('patient|assistance'),\n",
    "        df['KEYWORD'].str.contains('savings|discount'),\n",
    "        df['KEYWORD'].str.contains('free'),\n",
    "        df['KEYWORD'].str.contains('cost|price|prices')  \n",
    "    ],\n",
    "    choicelist=[1, 2, 3, 4, 5, 6], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 6. Age\n",
    "df['age'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('children|child|childhood|kids', case=False),\n",
    "        df['KEYWORD'].str.contains('adults', case=False)\n",
    "    ],\n",
    "    choicelist=[1, 2], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "# 6. cause\n",
    "df['cause'] = np.select(\n",
    "    condlist=[ # note you could use the case-insensitive search with `case=False`\n",
    "        df['KEYWORD'].str.contains('causes|cause', case=False),\n",
    "        df['KEYWORD'].str.contains('triggers', case=False)\n",
    "    ],\n",
    "    choicelist=[1, 2], # dummy variables\n",
    "    default=0 # you could set it to `np.nan` etc\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WEEK_OF_YEAR</th>\n",
       "      <th>CAMPAIGN</th>\n",
       "      <th>CAMPAIGN_TYPE</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Media_Cost</th>\n",
       "      <th>...</th>\n",
       "      <th>Visitor_Bounce</th>\n",
       "      <th>CPC</th>\n",
       "      <th>symptom</th>\n",
       "      <th>asthma</th>\n",
       "      <th>treatment</th>\n",
       "      <th>brand</th>\n",
       "      <th>chemical</th>\n",
       "      <th>payment</th>\n",
       "      <th>age</th>\n",
       "      <th>cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>symptoms of asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>breathing with asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhaler names</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>breathing problems asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/21/2017 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhaler otc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  WEEK_OF_YEAR  CAMPAIGN  CAMPAIGN_TYPE  \\\n",
       "0  5/21/2017 0:00            21        39              1   \n",
       "1  5/21/2017 0:00            21        39              1   \n",
       "2  5/21/2017 0:00            21        46              1   \n",
       "3  5/21/2017 0:00            21        40              1   \n",
       "4  5/21/2017 0:00            21        48              1   \n",
       "\n",
       "                     KEYWORD  NETWORK  POSITION  Clicks  Impressions  \\\n",
       "0         symptoms of asthma        1      2.08       3           51   \n",
       "1      breathing with asthma        1      2.00       1            4   \n",
       "2       asthma inhaler names        1      2.00       1            1   \n",
       "3  breathing problems asthma        1      1.00       1            1   \n",
       "4         asthma inhaler otc        1      1.70       1            3   \n",
       "\n",
       "   Media_Cost  ...    Visitor_Bounce   CPC  symptom  asthma treatment  brand  \\\n",
       "0        5.40  ...                 1   1.8        1       1         0      0   \n",
       "1        3.71  ...                 0  3.71        4       1         0      0   \n",
       "2        3.58  ...                 0  3.58        0       1         1      0   \n",
       "3        3.24  ...                 0  3.24        4       1         0      0   \n",
       "4        3.76  ...                 0  3.76        0       1         1      0   \n",
       "\n",
       "   chemical  payment  age  cause  \n",
       "0         0        0    0      0  \n",
       "1         0        0    0      0  \n",
       "2         2        0    0      0  \n",
       "3         0        0    0      0  \n",
       "4         0        0    0      0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.058824\n",
       "1    0.250000\n",
       "2    1.000000\n",
       "3    1.000000\n",
       "4    0.333333\n",
       "Name: CTR, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CTR'] = (df['Clicks']/df['Impressions'])\n",
    "df['CTR'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df.drop(labels=['DATE','WEEK_OF_YEAR','KEYWORD','Impressions','CPC','Page_Views', 'Clicks', 'Time_On_Site_Total','Visits', 'Visitor_Bounce'], axis=1) \n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0be8df34eb41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#identify traits of top 10% - not completed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CTR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtop10\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CTR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtop10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "#Identify mean of ctr\n",
    "df_mean = df['CTR'].mean()\n",
    "df_mean\n",
    "\n",
    "#identify traits of top 10% - not completed\n",
    "df3 = df2.sort_values('CTR', axis=0, ascending=False)\n",
    "top10=df3.nlargest(7000,'CTR')\n",
    "top10.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop(labels=['DATE','KEYWORD','Clicks','Impressions','CTR','CPC'], axis=1) \n",
    "\n",
    "X = df.drop(labels=['DATE','WEEK_OF_YEAR','KEYWORD','Impressions','CPC','Page_Views', 'Clicks', 'Time_On_Site_Total','Visits', 'Visitor_Bounce','CTR'], axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMPAIGN</th>\n",
       "      <th>CAMPAIGN_TYPE</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>symptom</th>\n",
       "      <th>asthma</th>\n",
       "      <th>treatment</th>\n",
       "      <th>brand</th>\n",
       "      <th>chemical</th>\n",
       "      <th>payment</th>\n",
       "      <th>age</th>\n",
       "      <th>cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAMPAIGN  CAMPAIGN_TYPE  NETWORK  symptom  asthma  treatment  brand  \\\n",
       "0        39              1        1        1       1          0      0   \n",
       "1        39              1        1        4       1          0      0   \n",
       "2        46              1        1        0       1          1      0   \n",
       "3        40              1        1        4       1          0      0   \n",
       "4        48              1        1        0       1          1      0   \n",
       "\n",
       "   chemical  payment  age  cause  \n",
       "0         0        0    0      0  \n",
       "1         0        0    0      0  \n",
       "2         2        0    0      0  \n",
       "3         0        0    0      0  \n",
       "4         0        0    0      0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.058824\n",
       "1    0.250000\n",
       "2    1.000000\n",
       "3    1.000000\n",
       "4    0.333333\n",
       "Name: CTR, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.loc[:,'CTR']\n",
    "\n",
    "#for y, take log(CTR)\n",
    "#y=df.loc[:,'Impressions']\n",
    "y.head()\n",
    "#X=.iloc[:,1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WEEK_OF_YEAR</th>\n",
       "      <th>CAMPAIGN</th>\n",
       "      <th>CAMPAIGN_TYPE</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Media_Cost</th>\n",
       "      <th>...</th>\n",
       "      <th>CPC</th>\n",
       "      <th>symptom</th>\n",
       "      <th>asthma</th>\n",
       "      <th>treatment</th>\n",
       "      <th>brand</th>\n",
       "      <th>chemical</th>\n",
       "      <th>payment</th>\n",
       "      <th>age</th>\n",
       "      <th>cause</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5/20/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma breathing treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>5/20/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 inhalation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5/20/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 manufacturer coupon</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5/20/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 manufacturer</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5/19/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma breathing treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>5/19/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>cause asthma</td>\n",
       "      <td>0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>5/18/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>competitor9 aqua</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>5/18/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>what is asthma symptoms</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>5/18/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>competitor5 inhaler</td>\n",
       "      <td>0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 inhaler coupon</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>childhood asthma</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 discounts</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthmatic symptoms</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>budesonide</td>\n",
       "      <td>0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>5/17/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma breathing treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>5/16/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>signs of asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>5/16/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 80 inhaler</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>5/16/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>medications product1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>competitor7 inhaler</td>\n",
       "      <td>0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>childhood asthma symptoms</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma cause</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 inhaler dosage</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 com</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>5/15/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>how to prevent asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>5/14/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma in adults</td>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>5/14/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>competitor7 inhaler</td>\n",
       "      <td>0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>5/14/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>asthmatic inhalers</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>5/14/2017 0:00</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>inflammation of lung</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>5/13/2017 0:00</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhalers</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>5/13/2017 0:00</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma coughing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76007</th>\n",
       "      <td>1/26/2016 0:00</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 medicine</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76052</th>\n",
       "      <td>1/25/2016 0:00</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 discount</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76155</th>\n",
       "      <td>1/24/2016 0:00</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 drug</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76226</th>\n",
       "      <td>1/23/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 coupons</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76239</th>\n",
       "      <td>1/23/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76252</th>\n",
       "      <td>1/23/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>signs of asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76268</th>\n",
       "      <td>1/23/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 dosage</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76271</th>\n",
       "      <td>1/23/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma symptoms in children</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76431</th>\n",
       "      <td>1/21/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma symptoms in children</td>\n",
       "      <td>1</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76648</th>\n",
       "      <td>1/19/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>how to use product1 inhaler</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76665</th>\n",
       "      <td>1/19/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 for asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76701</th>\n",
       "      <td>1/18/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma breathing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76789</th>\n",
       "      <td>1/17/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 help</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76792</th>\n",
       "      <td>1/17/2016 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 price</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77149</th>\n",
       "      <td>1/13/2016 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 inhalation</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77162</th>\n",
       "      <td>1/13/2016 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma inhaler</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77228</th>\n",
       "      <td>1/12/2016 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma medications</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77271</th>\n",
       "      <td>1/12/2016 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>qué es el asma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77446</th>\n",
       "      <td>1/10/2016 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>symptoms of asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77801</th>\n",
       "      <td>1/6/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>budesonide</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77810</th>\n",
       "      <td>1/6/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>what is product1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77868</th>\n",
       "      <td>1/5/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 coupons free</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77869</th>\n",
       "      <td>1/5/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma prevention</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77959</th>\n",
       "      <td>1/4/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 patient</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78013</th>\n",
       "      <td>1/4/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 manufacturer coupon</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78027</th>\n",
       "      <td>1/4/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>inhalation aerosol</td>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78033</th>\n",
       "      <td>1/4/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asthma coughing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78054</th>\n",
       "      <td>1/3/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78076</th>\n",
       "      <td>1/3/2016 0:00</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>what is asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78253</th>\n",
       "      <td>1/1/2016 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>product1 dosage</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1736 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE  WEEK_OF_YEAR  CAMPAIGN  CAMPAIGN_TYPE  \\\n",
       "117    5/20/2017 0:00            20        49              1   \n",
       "156    5/20/2017 0:00            20         8              0   \n",
       "196    5/20/2017 0:00            20         8              0   \n",
       "300    5/20/2017 0:00            20         8              0   \n",
       "391    5/19/2017 0:00            20        49              1   \n",
       "477    5/19/2017 0:00            20        41              1   \n",
       "627    5/18/2017 0:00            20        36              1   \n",
       "666    5/18/2017 0:00            20        39              1   \n",
       "698    5/18/2017 0:00            20        37              1   \n",
       "796    5/17/2017 0:00            20         8              0   \n",
       "797    5/17/2017 0:00            20        41              1   \n",
       "798    5/17/2017 0:00            20         8              0   \n",
       "849    5/17/2017 0:00            20        40              1   \n",
       "886    5/17/2017 0:00            20        36              1   \n",
       "991    5/17/2017 0:00            20        49              1   \n",
       "1104   5/16/2017 0:00            20        42              1   \n",
       "1205   5/16/2017 0:00            20         8              0   \n",
       "1256   5/16/2017 0:00            20         8              0   \n",
       "1315   5/15/2017 0:00            20        36              1   \n",
       "1370   5/15/2017 0:00            20        40              1   \n",
       "1446   5/15/2017 0:00            20        42              1   \n",
       "1453   5/15/2017 0:00            20         8              0   \n",
       "1546   5/15/2017 0:00            20         8              0   \n",
       "1547   5/15/2017 0:00            20        48              1   \n",
       "1558   5/14/2017 0:00            20        40              1   \n",
       "1563   5/14/2017 0:00            20        36              1   \n",
       "1578   5/14/2017 0:00            20        44              1   \n",
       "1672   5/14/2017 0:00            20        41              1   \n",
       "1750   5/13/2017 0:00            19        46              1   \n",
       "1764   5/13/2017 0:00            19        40              1   \n",
       "...               ...           ...       ...            ...   \n",
       "76007  1/26/2016 0:00             5         8              0   \n",
       "76052  1/25/2016 0:00             5         8              0   \n",
       "76155  1/24/2016 0:00             5         8              0   \n",
       "76226  1/23/2016 0:00             4         8              0   \n",
       "76239  1/23/2016 0:00             4         8              0   \n",
       "76252  1/23/2016 0:00             4        42              1   \n",
       "76268  1/23/2016 0:00             4         8              0   \n",
       "76271  1/23/2016 0:00             4        40              1   \n",
       "76431  1/21/2016 0:00             4        40              1   \n",
       "76648  1/19/2016 0:00             4         8              0   \n",
       "76665  1/19/2016 0:00             4         8              0   \n",
       "76701  1/18/2016 0:00             4        40              1   \n",
       "76789  1/17/2016 0:00             4         8              0   \n",
       "76792  1/17/2016 0:00             4         8              0   \n",
       "77149  1/13/2016 0:00             3         8              0   \n",
       "77162  1/13/2016 0:00             3        46              1   \n",
       "77228  1/12/2016 0:00             3        49              1   \n",
       "77271  1/12/2016 0:00             3        22              1   \n",
       "77446  1/10/2016 0:00             3        40              1   \n",
       "77801   1/6/2016 0:00             2        37              1   \n",
       "77810   1/6/2016 0:00             2         8              0   \n",
       "77868   1/5/2016 0:00             2         8              0   \n",
       "77869   1/5/2016 0:00             2        49              1   \n",
       "77959   1/4/2016 0:00             2         8              0   \n",
       "78013   1/4/2016 0:00             2         8              0   \n",
       "78027   1/4/2016 0:00             2        46              1   \n",
       "78033   1/4/2016 0:00             2        40              1   \n",
       "78054   1/3/2016 0:00             2        12              0   \n",
       "78076   1/3/2016 0:00             2        42              1   \n",
       "78253   1/1/2016 0:00             1         8              0   \n",
       "\n",
       "                            KEYWORD  NETWORK  POSITION  Clicks  Impressions  \\\n",
       "117      asthma breathing treatment        0      3.06       0           73   \n",
       "156             product1 inhalation        1      1.43       0           28   \n",
       "196    product1 manufacturer coupon        1      1.00       0            7   \n",
       "300           product1 manufacturer        1      1.00       0            1   \n",
       "391      asthma breathing treatment        0      3.19       0           60   \n",
       "477                    cause asthma        0      3.38       0           16   \n",
       "627                competitor9 aqua        1      3.00       0            2   \n",
       "666         what is asthma symptoms        0      1.13       0            8   \n",
       "698             competitor5 inhaler        0      6.37       0           19   \n",
       "796         product1 inhaler coupon        1      1.00       0            8   \n",
       "797                childhood asthma        0      1.25       0           16   \n",
       "798              product1 discounts        1      1.00       0            1   \n",
       "849              asthmatic symptoms        0      1.75       0           63   \n",
       "886                      budesonide        0      4.19       0           80   \n",
       "991      asthma breathing treatment        0      3.50       0            2   \n",
       "1104                signs of asthma        1      2.78       0           13   \n",
       "1205            product1 80 inhaler        1      1.00       0            1   \n",
       "1256           medications product1        1      1.00       0           26   \n",
       "1315            competitor7 inhaler        0      7.30       0           72   \n",
       "1370      childhood asthma symptoms        1      1.00       0            1   \n",
       "1446                   asthma cause        1      1.56       0            9   \n",
       "1453        product1 inhaler dosage        1      1.00       0            5   \n",
       "1546                   product1 com        1      1.00       0            2   \n",
       "1547          how to prevent asthma        1      1.24       0            8   \n",
       "1558               asthma in adults        1      1.15       0            6   \n",
       "1563            competitor7 inhaler        0      4.27       0           97   \n",
       "1578             asthmatic inhalers        0      2.00       0            5   \n",
       "1672           inflammation of lung        0      1.00       0            3   \n",
       "1750                asthma inhalers        0      3.58       0           12   \n",
       "1764                asthma coughing        1      1.82       0           33   \n",
       "...                             ...      ...       ...     ...          ...   \n",
       "76007             product1 medicine        0      1.00       0            3   \n",
       "76052             product1 discount        1      1.00       0            5   \n",
       "76155                 product1 drug        0      1.00       0            1   \n",
       "76226              product1 coupons        0      1.00       0            5   \n",
       "76239               product1 asthma        1      1.00       0            2   \n",
       "76252               signs of asthma        1      2.70       0            3   \n",
       "76268               product1 dosage        1      1.00       0           10   \n",
       "76271   asthma symptoms in children        1      1.70       0            7   \n",
       "76431   asthma symptoms in children        1      2.02       0            5   \n",
       "76648   how to use product1 inhaler        1      1.00       0            7   \n",
       "76665           product1 for asthma        1      1.00       0            2   \n",
       "76701              asthma breathing        1      1.75       0            8   \n",
       "76789                 product1 help        1      1.00       0            7   \n",
       "76792                product1 price        1      1.00       0            2   \n",
       "77149           product1 inhalation        0      1.00       0            2   \n",
       "77162                asthma inhaler        1      1.67       0           11   \n",
       "77228            asthma medications        1      2.40       0           22   \n",
       "77271                qué es el asma        1      1.50       0            2   \n",
       "77446            symptoms of asthma        1      3.62       0           34   \n",
       "77801                    budesonide        1      1.25       0          135   \n",
       "77810              what is product1        0      1.00       0            2   \n",
       "77868         product1 coupons free        1      1.00       0            1   \n",
       "77869             asthma prevention        1      1.00       0            7   \n",
       "77959              product1 patient        0      1.00       0            1   \n",
       "78013  product1 manufacturer coupon        0      1.00       0            2   \n",
       "78027            inhalation aerosol        1      1.15       0            8   \n",
       "78033               asthma coughing        1      3.33       0           43   \n",
       "78054                   product1 40        1      1.00       0            1   \n",
       "78076                what is asthma        1      3.27       0           88   \n",
       "78253               product1 dosage        1      1.20       0            5   \n",
       "\n",
       "       Media_Cost ...       CPC  symptom  asthma  treatment brand  chemical  \\\n",
       "117           0.0 ...   #DIV/0!        4       1          4     0         0   \n",
       "156           0.0 ...   #DIV/0!        0       0          9     1         0   \n",
       "196           0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "300           0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "391           0.0 ...   #DIV/0!        4       1          4     0         0   \n",
       "477           0.0 ...   #DIV/0!        0       1         14     0         0   \n",
       "627           0.0 ...   #DIV/0!        0       0          0     0         6   \n",
       "666           0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "698           0.0 ...   #DIV/0!        0       0          1     3         0   \n",
       "796           0.0 ...   #DIV/0!        0       0          1     1         0   \n",
       "797           0.0 ...   #DIV/0!        0       1          0     0         0   \n",
       "798           0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "849           0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "886           0.0 ...   #DIV/0!        0       0          0     0         4   \n",
       "991           0.0 ...   #DIV/0!        4       1          4     0         0   \n",
       "1104          0.0 ...   #DIV/0!        2       1          0     0         0   \n",
       "1205          0.0 ...   #DIV/0!        0       0          1     1         0   \n",
       "1256          0.0 ...   #DIV/0!        0       0          6     1         0   \n",
       "1315          0.0 ...   #DIV/0!        0       0          1     4         0   \n",
       "1370          0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "1446          0.0 ...   #DIV/0!        0       1         14     0         0   \n",
       "1453          0.0 ...   #DIV/0!        0       0          1     1         0   \n",
       "1546          0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "1547          0.0 ...   #DIV/0!        0       1          0     0         0   \n",
       "1558          0.0 ...   #DIV/0!        0       1          0     0         0   \n",
       "1563          0.0 ...   #DIV/0!        0       0          1     4         0   \n",
       "1578          0.0 ...   #DIV/0!        0       1          1     0         0   \n",
       "1672          0.0 ...   #DIV/0!        5       0          0     0         0   \n",
       "1750          0.0 ...   #DIV/0!        0       1          1     0         0   \n",
       "1764          0.0 ...   #DIV/0!        3       1          0     0         0   \n",
       "...           ... ...       ...      ...     ...        ...   ...       ...   \n",
       "76007         0.0 ...   #DIV/0!        0       0          6     1         0   \n",
       "76052         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "76155         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "76226         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "76239         0.0 ...   #DIV/0!        0       1          0     1         0   \n",
       "76252         0.0 ...   #DIV/0!        2       1          0     0         0   \n",
       "76268         0.0 ...   #DIV/0!        0       0          2     1         0   \n",
       "76271         0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "76431         0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "76648         0.0 ...   #DIV/0!        0       0          1     1         0   \n",
       "76665         0.0 ...   #DIV/0!        0       1          0     1         0   \n",
       "76701         0.0 ...   #DIV/0!        4       1          0     0         0   \n",
       "76789         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "76792         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "77149         0.0 ...   #DIV/0!        0       0          9     1         0   \n",
       "77162         0.0 ...   #DIV/0!        0       1          1     0         0   \n",
       "77228         0.0 ...   #DIV/0!        0       1          6     0         0   \n",
       "77271         0.0 ...   #DIV/0!        0       2          0     0         6   \n",
       "77446         0.0 ...   #DIV/0!        1       1          0     0         0   \n",
       "77801         0.0 ...   #DIV/0!        0       0          0     0         4   \n",
       "77810         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "77868         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "77869         0.0 ...   #DIV/0!        0       1          0     0         0   \n",
       "77959         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "78013         0.0 ...   #DIV/0!        0       0          0     1         0   \n",
       "78027         0.0 ...   #DIV/0!        0       0          9     0         0   \n",
       "78033         0.0 ...   #DIV/0!        3       1          0     0         0   \n",
       "78054         0.0 ...   #DIV/0!        0       0          3     1         0   \n",
       "78076         0.0 ...   #DIV/0!        0       1          0     0         0   \n",
       "78253         0.0 ...   #DIV/0!        0       0          2     1         0   \n",
       "\n",
       "       payment  age  cause  CTR  \n",
       "117          0    0      0  0.0  \n",
       "156          0    0      0  0.0  \n",
       "196          1    0      0  0.0  \n",
       "300          0    0      0  0.0  \n",
       "391          0    0      0  0.0  \n",
       "477          0    0      1  0.0  \n",
       "627          0    0      0  0.0  \n",
       "666          0    0      0  0.0  \n",
       "698          0    0      0  0.0  \n",
       "796          1    0      0  0.0  \n",
       "797          0    1      0  0.0  \n",
       "798          4    0      0  0.0  \n",
       "849          0    0      0  0.0  \n",
       "886          0    0      0  0.0  \n",
       "991          0    0      0  0.0  \n",
       "1104         0    0      0  0.0  \n",
       "1205         0    0      0  0.0  \n",
       "1256         0    0      0  0.0  \n",
       "1315         0    0      0  0.0  \n",
       "1370         0    1      0  0.0  \n",
       "1446         0    0      1  0.0  \n",
       "1453         0    0      0  0.0  \n",
       "1546         0    0      0  0.0  \n",
       "1547         0    0      0  0.0  \n",
       "1558         0    2      0  0.0  \n",
       "1563         0    0      0  0.0  \n",
       "1578         0    0      0  0.0  \n",
       "1672         0    0      0  0.0  \n",
       "1750         0    0      0  0.0  \n",
       "1764         0    0      0  0.0  \n",
       "...        ...  ...    ...  ...  \n",
       "76007        0    0      0  0.0  \n",
       "76052        4    0      0  0.0  \n",
       "76155        0    0      0  0.0  \n",
       "76226        1    0      0  0.0  \n",
       "76239        0    0      0  0.0  \n",
       "76252        0    0      0  0.0  \n",
       "76268        0    0      0  0.0  \n",
       "76271        0    1      0  0.0  \n",
       "76431        0    1      0  0.0  \n",
       "76648        0    0      0  0.0  \n",
       "76665        0    0      0  0.0  \n",
       "76701        0    0      0  0.0  \n",
       "76789        0    0      0  0.0  \n",
       "76792        6    0      0  0.0  \n",
       "77149        0    0      0  0.0  \n",
       "77162        0    0      0  0.0  \n",
       "77228        0    0      0  0.0  \n",
       "77271        0    0      0  0.0  \n",
       "77446        0    0      0  0.0  \n",
       "77801        0    0      0  0.0  \n",
       "77810        0    0      0  0.0  \n",
       "77868        1    0      0  0.0  \n",
       "77869        0    0      0  0.0  \n",
       "77959        3    0      0  0.0  \n",
       "78013        1    0      0  0.0  \n",
       "78027        0    0      0  0.0  \n",
       "78033        0    0      0  0.0  \n",
       "78054        0    0      0  0.0  \n",
       "78076        0    0      0  0.0  \n",
       "78253        0    0      0  0.0  \n",
       "\n",
       "[1736 rows x 24 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checking for 0s\n",
    "df.loc[df['Clicks'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y,\n",
    "test_size=0.3,\n",
    "random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.29\n",
      "Train set RMSE of rf: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a random forests regressor 'rf' 400 estimators\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "min_samples_leaf=0.12,\n",
    "random_state=SEED)\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train=rf.predict(X_train)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAD8CAYAAAABgWFAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xe8XFW5xvFfJNIM5UYEqZcWRAghQEACqKABQVCI4oMRhAhy6b1I1YggVRQBRWpUBHmpRq4IiAQw9JIQAoKUXJGgEkoEQ5Pk/rHWIZPZp+yc5Mw5s+f5fj7nc2b27LLmJeTN3ntmPf1mz56NmZlZVX2gtwdgZmbWk9zozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0vr39gAMAE9PY2bWPf26WsGNro+YNm1abw+hT1lmmWWYPn16bw+jT3FNilyTolaqyQorrFBqPV+6NDOzSnOjMzOzSnOjMzOzSuvXbDE9kt4DJpPuLz4B7BERMyWtBJwPrENq4DcCR0XEO5IWBy4ChpBuXL4GbBsRb0h6AxgO/DIfYhVgRv6ZDnwTuDEiBufjbwGcDSyZ1z87Ii7Mr40BjgZWjYh/5mVvRMSALt7W7H5d3k41M6uWF16Yv88m5Ht0Xf7t2YxndG9GxNDceN4B9pXUD7gOuCEiBgFrAQOAU/I2hwD/iIj18nZ7Ae+27TAiJud9DgXGkRrk0IgYUXtgSR8FrgD2jYi1gS2AfSRtX7PadOCIHnjfZmbWDc3Y6GrdBawJfAZ4KyIuA4iI94DDgD3z2dzywAttG0XEkxHxdjeOdwAwNiIezvuZTjqDO6ZmnUuBXSQN7Mb+zcxsAWvaRiepP7Ad6TLmusBDta9HxL+Av5Ia4aXAtyTdI+lkSYO6edjCcYAH8/I2b+TjHdLNY5iZ2QLUjN+jW0zSxPz4LuASYD/a/9J1P2B2REyUtDqwDTACeEDS8Ih4Yh6P3a+D49Qv+zEwUdIPOtqRpP8B/gcgIuZxGGZmzW+ZZZZpyHGasdG9me+lvU/SFODLdcuWBFYGngGIiDdI9/GukzQL+DzpwyzzYgowjHQfr81GwOO1K0XEa5KuAPbvaEf5AywX5qfN9YkgM7MFYH6/2N5qXxi/DVhc0u4AkhYCfkC6nzZT0uaS/iu/tjDpk5n/143jnA+MljQ07+vDwOnAGe2sezawD835jwkzs8qoRKOLiNnASOArkv4CPAW8BRyXV1kDuEPSZOAR0n21a7txnBeB3YCLJP0ZuBu4NCJ+286604HrgUXm/R2ZmdmC0nTfo6uo2Z7rcm6tNF9fWa5JkWtS1Eo1qfL36MzMzEpzozMzs0pzozMzs0pzozMzs0pzozMzs0pzozMzs0pzozMzs0rzrB19xIorlpvKZn7Mb/aTmVkz8hmdmZlVWp85o5M0G7g8Ir6en/cHXgTui4gd5mE/44EjI+JBSb8DvhYRr83jWAaQ5socQZpK7GVSGOt987ifQ4ELI2LmvGxnZmYLTl86o/s3MFjSYvn51tSEpXZHRHx+XptcdjHwCjAoItYFRgPdyZM4FFi8G9uZmdkC0mfO6LKbgO2Ba4BRwJXAJwEkfQg4F1iPNO4xEfGb3BgvIyUSPAG0NUokTQWGRcR0STeQYnsWBc7JMTkFktYAPgHsGhGzACLiWeDZ/PrhwJ559Ysj4kd5bAGsBCwEfA9YDlgBuF3S9IjYqu44Dc+ja1T204LQv3//phpvI7gmRa5JkWtS1Nca3a+Bb0u6ERhCSur+ZH7teOCPEbGnpKWB+yX9gRSFMzMihkgaAjzcwb73jIhXcmN8QNK1EfFyO+utC0yMiPfqX5C0EfANUiPsB9wn6Q5gdWBaRGyf11sqImbkprhVTjKYS2/k0TXTRK+tNDFtWa5JkWtS1Eo1aco8uoh4FFiVdDb3u7qXtwGOyeni40lnZqsAnwIur9n+0Q52f7CkScC9pDO7Qd0Y4hbA9RHx75og108Ck4ERkk6X9MmImNGNfZuZWQ/oU40uGwecRbpsWasf8OWIGJp/VomItoTwTs+IJG1J+mDJ8IhYn5RJt2gHq08B1pfUXm3ajYOIiKdISeOTgVMlfbuz8ZiZWeP0xUZ3KXBSREyuW34zcJCkfgCSNsjL7wR2zcsGky551lsKeDWnja8NbNrRwSPiGVIw63drjjVI0o75WDtJWjzflxsJ3CVpBdLl08tJTXrDvLvXgSXm7e2bmdmC1Nfu0RERfwPOaeel7wE/Ah7NDWgqsAPwU+AySY8CE4H729n298C+eZ0nSZcvO/NN0tcLnpY0kzlfL3hY0tiaY1wcEY9I+hxwpqRZwLvAfvn1C4GbJL1Y/2GUev4yt5lZz3DCeN/ghPE6rXRDvSzXpMg1KWqlmjhh3MzMjD546bKRJN0HLFK3+Ovt3B80M7Mm1dKNLiI+0dtjMDOznuVLl2ZmVmludGZmVmludGZmVmludGZmVmludGZmVmludGZmVmkt+/UCSbsDR5ImhH6UlCd3ArAwacqvXSPiH5LGAG9ExFl5u8dIU4+9RF0GXURclaN8zgYGANOB0RHxYiPfm5mZzdGSjU7SuqR8u81zKOtAUsPbNCJmS/omcDRwRCe72Za6DDpJHySFw+4YES9J2gU4hTlBrbVjmCt41UGJc3N4ZJFrUuSaFLkmRS3Z6IDPANe0BaLmQNb1gKskLU86q3uui31MBs6SdDpwY0TcldMTBgO3SoJ0ptfu2Vx98GqrzE1XVivN11eWa1LkmhS1Uk3KBq+2aqPrRzHD7lzg7IgYl/PrxuTl/2Hue5mLQsqgy5cpP0/KoLsFuB6YEhHDe3DsZmY2D1r1wyi3AZL0YdKDgaTMuhfy63vUrDuVnC8naUNgtfy4vQy6J4GPSBqe1/lgvkxqZma9pCUbXURMId07u0PSJNKHR8YAV0u6i/QhkjbXAgMlTSTlzD2Vl68H3J+XHw+cHBHvADsDp+f9TgQ2a8BbMjOzDjiPrm9wHl2dVrrPUJZrUuSaFLVSTZxHZ2ZmhhudmZlVnBudmZlVmhudmZlVmhudmZlVmhudmZlVmhudmZlVmhudmZlVmhudmZlVWqtO6jxPJN0ArEya0PmciLhQ0l7At4BpwF+AtyPiQEkfAS4AVsmbHxoRE3pj3GZm5jO6svaMiI2AYcDBklYETgQ2BbYG1q5Z9xzghxGxMfBl4OJGD9bMzObwGV05B0samR+vDHwduCMiXgGQdDWwVn59BLBOzqMDWFLSEhHxeu0OHbzaOYdHFrkmRa5JkWtS5EbXhZxNNwIYHhEzJY0nxfF8vINNPpDXfbOz/Tp4tXOtNDFtWa5JkWtS1Eo1KRu86kuXXVsKeDU3ubVJlysXBz4t6b8k9SddomxzC3Bg2xNJQxs6WjMzm4vP6Lr2e2BfSY+SzuTuJQW0fh+4j/RhlMeBGXn9g4Hz8/r9gTuBfRs9aDMzS9zouhARbwPb1S+X9GD+9GV/4HrSmRwRMR3YpbGjNDOzjvjSZfeNyenijwHPATf08njMzKwdPqPrpog4srfHYGZmXfMZnZmZVZobnZmZVZobnZmZVZobnZmZVZobnZmZVZobnZmZVZobXQ+RNFpSuYnYzMysx7jR9ZzRgBudmVkva9ovjEtalTQP5X3ABsBTwO7AkcAXgMWAu4F9gNWBqyNiw7ztIODXEbGRpKnAFcBWwAdJ0TmnAmsCZ0bEBXmbowABiwDXR8R38hhuAv4EbEaaA3NHYHtSdt2vJL1JiTQDMzPrGc1+Rvcx4MKIGAL8C9gfOC8iNo6IwaRmt0NEPAPMqEkS+AYwtmY/z0fEcOCuvHxnUkrBSQCStgEGAZsAQ4GNJH0qbzsIOD8i1gVeA74cEdcADwK7RsRQNzkzs97TtGd02fMRMSE/vpyUHPCcpKNJUToDgSnAb0lJ39+QdDhp0uVNavYzLv+eDAzIIamvS3pL0tLANvnnkbzeAFKD+yvwXERMzMsfAlYtM3AHr3bO4ZFFrkmRa1LkmhQ1e6Ob3c7znwDDIuJ5SWOARfNr1wLfAf4IPBQRL9ds93b+Pavmcdvz/kA/4NSI+FntwfKly9r13yOdRXbJwauda6XwyLJckyLXpKiVatIqwaurSBqeH48i3SsDmC5pAOkSJAAR8RZwM/BT4LJ5PM7NwJ55n0haUdKyXWzzOrDEPB7HzMwWsGZvdE8Ae+SQ04GkJnYR6RLkDcADdev/inTWd8u8HCQibiF9YOUeSZOBa+i6iY0FLpA0UVKpszwzM1vw+s2eXX/1rznky4Y35g+dlN3mSGCpiDixxwbWPbOnTZvW22PoU1rp8ktZrkmRa1LUSjXJly77dbVes9+jK03S9cAawGd6eyxmZtY4TXtGVzE+o6vTSv8qLcs1KXJNilqpJmXP6Jr9Hp2ZmVmn3OjMzKzS3OjMzKzS3OjMzKzS3OjMzKzS3OjMzKzSKtPoJI2VtHPXa87zfr8o6ZhubjtVkmdXNTPrRS3zhfHuiohxzEk3MDOzJtO0jU5SW8jqbOBRUnLAp3IMz0eBo3MuXGehqb8nTQS9KTCJNNnzd4FlSVly90saTUpDOFDScsAFpCBXgP0i4m5JNwArk5ISzsnJBGZm1gc0ZaOTtC5wPLB5REyXNBA4G1ge2AJYm3QWdk1daGo/YFwOTf0rKUX8K6RcuAeAr+XtvwgcB+xUd+gfA3dExEhJC5Fy6QD2jIhX8uTND0i6ti4GqL334Dy6TjhTq8g1KXJNilyToqZsdKT5Kq+JiOkAuckA3BARs4DH89kXdB2aOhlA0hTgtoiYnRMKVu3guLvnY74HzMjLD5Y0Mj9eOe+/00bnPLrOtdI0RmW5JkWuSVEr1aRsHl2zNrp+FENXYe4Q1H41v8uEptaGrrYFrnZJ0pbACGB4RMyUNJ45Ya9mZtbLmvVTl7cBkvRh0oOBnazbndDUzo67X97PQpKWBJYCXs1Nbm3S/T4zM+sjmrLRRcQU4BTgDkmTSPfnOlq3O6GpHTkE2Crv5yFgXdIHWvrn8NfvAfd2c99mZtYDHNPTNzimp04r3WcoyzUpck2KWqkmjukxMzPDjc7MzCrOjc7MzCrNjc7MzCrNjc7MzCrNjc7MzCrNjc7MzCqtJRudpFUlPdaA4/RIRp6ZmZXXko2ujJxOYGZmTa5ZJ3VeEPpL+jmwAfAUKZXgceBSUtrBeZKWIEXpLAw8DXw9z2k5FvgXMIya7DtJ/YBzSSkHz1HiG/tmZtazWvmM7mPAhRExhNS09s/L34qILSLi18B1EbFxRKwPPAHsVbN9W/bdDsBpednIvN/1gL2BzXr+bZiZWWda+Yzu+YiYkB9fDhycH19Vs85gSScDS5Ny7G6uea297LtPAVfmrLppkv7Y0cEdvNo5h0cWuSZFrkmRa1LUyo2ufjbrtuf/rlk2FtgpIiZJGg1sWfNae9l37e23XQ5e7VwrTUxblmtS5JoUtVJNygavtvKly1UkDc+PRwF/amedJYAXJX0Q2LXEPu8Evpqz6pYHtlowQzUzs+5q5Ub3BLBHzpEbCPy0nXVOBO4DbgX+XGKf1wN/ASbn/d2xYIZqZmbd5Ty6vsF5dHVa6fJLWa5JkWtS1Eo1cR6dmZkZbnRmZlZxbnRmZlZpbnRmZlZpbnRmZlZpbnRmZlZpbnRmZlZpbnRmZlZpfb7RSVpa0v5dr1l6f4dKWnxB7a+3j2NmZp3r842OlBxQaHTzEYx6KNCIBtSo45iZWSeaIb3gNGANSROBd4E3gBeBocA6knYjRewsTJqXcv+IeE/ST4GNgcWAayLiO5IOBlYAbpc0PSK2kvQGcD4wAngVOA44A1gFODQixuWmehopvWAR4PyI+JmkLYExwHRgMPAQsBtwUP1xerRCZmbWoWY4ozsGeCYihgJHAZsAx0fEOpI+DuwCbJ5ff485KQPHR8QwYAjwaUlDIuLHwDRgq5rm8yFgfERsBLwOnAxsTQpRPSmvsxcwIyI2JjXPvSWtll/bgHT2tg6weh5Le8cxM7Ne0AxndPXuj4jn8uPPAhsBD0iCdPb2z/yacrhpf1Ia+DrAo+3s7x3g9/nxZODtiHhX0mRg1bx8G2CIpJ3z86WAQXnb+yPib/mAE/M27UX+zMXBq51zeGSRa1LkmhS5JkXN2Ohqg1H7AT+PiGNrV8hnW0cCG0fEq5LGAot2sL93I6ItwmEWOVA1ImZJaqtPP+CgiKhNGCdfuqwNYH2PkjV18GrnWmkG9rJckyLXpKiValKl4NXXSQGo7bkN2FnSsgCSBkr6b2BJUkOcIWk5YLuS++vIzcB+OYAVSWtJ+tB8jNvMzBqkzze6iHgZmCDpMeDMutceB04AbskBqrcCy0fEJOARYApwKTChZrMLgZsk3T4Pw7gYeBx4OI/jZ3R95tad45iZ2QLm4NW+wcGrdVrp8ktZrkmRa1LUSjVx8KqZmRludGZmVnFudGZmVmludGZmVmludGZmVmludGZmVmludGZmVmludGZmVmkt3+gkjZa0Qs3zqZI8I6qZWUW0fKMDRpOy48zMrIKaMb2gFEk3ACuTUgvOAS7JP8OA2aQ5MJ/Pz38l6U1geN78IElfAD4IfCUi/ixpDLAaKfJnLeBwYFPShNEvAF/I8T7fBr5Aigy6G9inJh3BzMwarMpndHvmMNVhpATyocCKETE4ItYDLouIa4AHgV0jYmhEvJm3nR4RGwI/JcX9tFkD2B7YEbgcuD3v6828HOC8iNg4IgaTmt0OPfs2zcysM5U9owMOljQyP14ZWBhYXdK5wP8Ct3Sy7XX590PAl2qW31QTyroQcwe2rpofbyXpaGBxYCApQeG39Qdw8GrnHB5Z5JoUuSZFrklRJRtdDkQdAQyPiJmSxgOLAOsDnwMOAATs2cEu2sJU64NUa0NZ6wNb+0taFPgJMCwins+XO9sNfHXwaudaaQb2slyTItekqJVqUqXg1e5YCng1N7m1SffSlgE+EBHXAicCG+Z1F2RAaltTmy5pALDzAtqvmZl1UyXP6EiXFPfNYaxPAvcCKwLjJbU192Pz77HABXUfRumWiHhN0kWkS5lTgQfmZ39mZjb/HLzaNzh4tU4rXX4pyzUpck2KWqkmDl41MzPDjc7MzCrOjc7MzCrNjc7MzCrNjc7MzCrNjc7MzCrNjc7MzCrNjc7MzCrNja4DkpaWtH9vj8PMzOaPG13Hlgbc6MzMmlzTzXUp6UNAACuRonK+B3w1Ikbm17cG9ouIL0l6AziflGTwKnAccAawCnBoRIyTNBoYSUo3WA24IiK+C5wGrCFpInArcHTedjtScOvJEXFVTkr4LvAPUubddaS5Lg8h5dHtFBHP9GhRzMysQ03X6IBtgWkRsT2ApKWA70r6SES8BHwDuCyv+yFgfER8S9L1wMnA1sA6wM+BcXm9TYDBwEzgAUn/CxwDDI6Iofk4XyY1svVJSQgPSLozb78+8HHgFeBZ4OKI2ETSIcBBwKH1b8J5dJ1zplaRa1LkmhS5JkXN2OgmA2dJOh24MSLukvRLYDdJl5ESCHbP677D3OGob9cEp65as89bI+JlAEnXAVsAN9Qddwvgyoh4D/iHpDuAjYF/AQ9ExIt5+2eYE+o6GdiqvTfhPLrOtdLEtGW5JkWuSVEr1aSyeXQR8RSwEamJnCrp26QzuN2AUcDVEfGfvHp9OOr7wanM3eTrIxzai3TobIbst2sez6p5Xn8cMzNrsKZrdJJWAGZGxOXAWcCGETENmAacQMqXm1dbSxooaTFgJ2ACxUDWO4FdJC0k6SPAp4D7u/9OzMysEZrxbGM94ExJs4B3gf3y8l8BH4mIx7uxzz8BvwTWJH0Y5UEASRMkPQbcRPowynBgEumM7+iI+HtOMDczsz6qMsGrks4DHomIS+Zxu9HAsIg4sEcGVo6DV+u00n2GslyTItekqJVqUjZ4tRnP6AokPQT8Gziit8diZmZ9S2XO6Jqcz+jqtNK/SstyTYpck6JWqknZM7qm+zCKmZnZvHCjMzOzSnOjMzOzSnOjMzOzSnOjMzOzSuvzXy+QNBs4OyKOyM+PBAZExBhJY4C9gZdqNjkVODY/XhN4AXgTeJT0ZfNvRMRESf2BGcA+eZaVtq8p7B0RD0vaCTgJWJj0xfQTI+KGvN5Y4NN5+37A4RFxW35tPHBkRDwoaVVS8sGBEXHzgq6NmZl1rRnO6N4GviSpo+m4fxgRQ2t+rmp7DDwI7Jqf7w7cDWyWt1sfeLLteY7/WR2YJGl90vRiO0bE2sAXSRNJD6k57lH5GIcCF9QPStJKwM3AEW5yZma9pxka3X9Is/wftgD2NYE5jW4zUoMamp9vAjyc0wmOBL4fEc8B5N+nAke1s897gBXrln2UlGBwQkSMK25iZmaN0gyNDlJ46q45e67eYZIm5p/bu9hP7RndZqSJmt+WtER+PiG/ti7wUN22D+bl9balGOnzC+C8iLi6i/GYmVkP6/P36AAi4l+SfgEcTLrfVuuHEXFWyf1MlbSwpI8Ca5MuXT4AfILU6M7Nq/ajGNVTv+xMSWcAywKb1q37B+DrksZGxMz2xuLg1c45PLLINSlyTYpck6KmaHTZj4CHmZMe3l33ADsDL0bEbEn3ApuTLl3em9eZAgwjfYClzYZAbTLCUcB1pOb7c1JGXpszSPl4V0vasSYf730OXu1cK01jVJZrUuSaFLVSTSoXvBoRrwAB7DWfu5pAut93T35+DymR/O8R8VpedhZwbP7UJPn3ccAP6sY0CzgH+ICkz9Ud5zBS+vglkrqci83MzHpG0zS67AdA/Tl57T26iW3NqRMTSJ+uvAcgIl4EFiLdvyMvmwh8C/itpD8DvyXlz02s31lOMD+ZlFdXv3wPYHnSGZ6ZmfUCpxf0DU4vqNNKl1/Kck2KXJOiVqqJ0wvMzMxwozMzs4pzozMzs0pzozMzs0pzozMzs0pzozMzs0pzozMzs0pzozMzs0pzozMzs0orNalznu3/R8DGpCDUqcChEfGUpMNIWW3LRcSMvP6WwO3ANyPikrxsA9KkzEdFxFl1Kd2zgAMi4p68bn/g78BFEXFszTjGMye9ewBwJrANaU7JWcAFEXFRngbsOeDgiDg3b3se8GBEjG3n/Z1Pmth5YWA1UqoBwBXARhGxS15vSeARYATwnfbGX/e+AGZGRFs0kJmZNViXZ3R5QuLrgfERsUZErEOa4Hi5vMooUtTNyLpNJwO71Dz/KjCpbp22lO5jgJ/VLN+G1GzUyYTIFwOvAoMiYgNSLtzAmtf/CRwiaeGu3mNEHJDH8XngmZqE8jOBlSSNyKueBFzaFsjayfiPqkk8d5MzM+tFZc7otgLejYgL2ha0TW4saQ1gACmy5jhgbM12fwWWlLQcqelsC/yug2PcCaxZ83wUKRVgP1LW2z21K+fjbgJ8LScIEBEvAafXrPYSaQLnPYCLSrzPghzjsx9whaTRwGeZO46no/GbmVkfUabRDaaYtt1mFHAlcBfwMUnLRsQ/a16/BvgK6XLfw6TLnu35AukMEEmLkRrKPsDS+Rj31K2/LjCprcl14jTgJkmXdrFehyLiUUk3A7cBO0XEO52NPztT0gn58ZSI2LV+Awevds7hkUWuSZFrUuSaFM1v8OpXgZERMUvSdaSmdn7N6wFcRUrzvpKU4l2rrSG8xJycuR2A2yNipqRrgRMlHRYR73U0CEnH52MvGxHvJ/FFxHOS7ge+Nl/vMr2n7SLi9hLjh3Tp8prOdujg1c610gzsZbkmRa5JUSvVpGzwaplGN4WUyD0XSUOAQcCtkiB9kONZahpdRPxd0rvA1sAhFBtdew1hFLC5pKn5+YdJl0//ULPO48D6kj4QEbMi4hTgFElvtDP+75POLO8s8V47Miv/1OuyoZmZWe8q8/WCPwKLSNq7bYGkjUn30MZExKr5ZwVgRUn/Xbf9t4FvdXZGVrPfJYEtgFXa9gscQGp+74uIp4EHgZMlLZS3XZR2coki4s+kxrhDifdqZmYV0+UZXf5AxkjgR5KOAd4ifb1gS9KHRWpdT7qceV/N9ndT3peAP0ZE7b283wBnSFqkbt1vkj4V+bSkV4A3Sang7TmFdJ+wUWrv0QFs0sG9PTMz62FOGO8bnDBep5XuM5TlmhS5JkWtVBMnjJuZmTH/n7psOjWzoNQ6JyIu643xmJlZz2q5RhcRB/T2GMzMrHF86dLMzCrNjc7MzCrNjc7MzCrNjc7MzCqtz34YpeoZeGZm1hh98oyuFTLwzMysMfrqGV3LZuCZmdmC1VcbXeUz8JxH1zlnahW5JkWuSZFrUtRXG11nKpGB5zy6zrXSfH1luSZFrklRK9WkbB5dn7xHR8rA26h+YV0G3lRS06uP8Pk70JaBd1s7+z4qIoZGxNYR8VheNgoYkff5EHMy8Gq9n4GXj3NKvte3ZDvH+D4pSaGv1tfMrGX01b+InYFnZmYLRJ+8dOkMPDMzW1CcR9c3OI+uTivdZyjLNSlyTYpaqSbOozMzM8ONzszMKs6NzszMKs336PoG/0cwM+se36NrBpIeIv3H8k/+cU1cE9fENSn50yU3OjMzqzQ3OjMzqzQ3ur7hwq5XaTmuSZFrUuSaFLkmdfxhFDMzqzSf0ZmZWaX1ybkuq0rStqSJqRcCLo6I0+peXwT4BSm54WVgl4iY2uhxNlKJmhxOmmP0P6RopT0j4v8aPtAG6qomNevtDFwNbBwRDzZwiA1Vph6SBIwhfVVnUkR0GpNVBSX+31kF+DkpY3Mh4JiI6CiIutJ8RtcgOfHgfGA7YB1glKR16lbbC3g1ItYEfsjc6eWVU7ImjwDDImIIKVT3jMaOsrFK1gRJSwAHUzOZeRWVqYekQcCxwOYRsS5waMMH2mAl/5ycAEREbECa+P4njR1l3+FG1zibAE9HxLMR8Q7wa2DHunV2JP0LDNJf6p+VVOp7Ik2qy5pExO0RMTM/vRdYqcFjbLQyf04Avkdq+m81cnC9oEw99gbOj4hXASLinw0eY28oU5fZzMnLXApo2Znj3egaZ0Xg+Zrnf8vL2l0nIv4DzCCFwFZVmZrU2gu4qUdH1Pu6rImkDYCVI+LGRg6sl5T5M7IWsJakCZLuzZf0qq7GVNPmAAABtUlEQVRMXcYAu0n6G/A74KDGDK3vcaNrnPbOzOo/8lpmnSop/X4l7QYMI+UBVlmnNckJ9z8EjmjYiHpXmT8j/YFBpLzKUcDFkpbu4XH1tjJ1GQWMjYiVgM8Dv8x/flpOS77pXvI3YOWa5ytRvJTw/jqS+pMuN7zSkNH1jjI1QdII4Hjgi3UBuVXUVU2WAAYD4yVNBTYFxkka1rARNlbZ/29+ExHvRsRzwJOkxldlZeqyFxAAEXEPsCiwTENG18f4U5eN8wAwSNJqwAukm8P1nwwbB+wB3APsTEo+r/IZXZc1yZfpfgZs2yL3XjqtSUTMoOYvK0njgSMr/KnLMv/f3EA+e5G0DOlS5rMNHWXjlanLX4HPkurycVKje6mho+wjfEbXIPme24HAzcATaVFMkXSSpC/m1S4BPizpaeBw4JjeGW1jlKzJmcAA4GpJEyWN66XhNkTJmrSMkvW4GXhZ0uPA7cBREfFy74y4MUrW5Qhgb0mTgCuB0RX/h3OHPDOKmZlVms/ozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0tzozMys0v4f8u6dL7gVaXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_,\n",
    "index = X.columns)\n",
    "# Sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE = 0.1352047043410771\n"
     ]
    }
   ],
   "source": [
    "def RMSE(x,y): \n",
    "    return np.mean((x - y)**2)**0.5\n",
    "rfSearch200 = RandomForestRegressor(n_estimators=200,random_state=0,\n",
    "                                    oob_score=True,n_jobs=-1,max_features=6)\n",
    "rfSearch200.fit(X, y)\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'reg:squarederror'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.327547+0.000172028\ttest-rmse:0.327863+0.000326249\n",
      "[10]\ttrain-rmse:0.231656+0.000567622\ttest-rmse:0.235642+0.000424434\n",
      "[20]\ttrain-rmse:0.226217+0.000773803\ttest-rmse:0.232139+0.000568416\n",
      "[30]\ttrain-rmse:0.222546+0.000437972\ttest-rmse:0.230772+0.000357917\n",
      "[40]\ttrain-rmse:0.219767+0.000510518\ttest-rmse:0.230142+0.000360515\n",
      "[50]\ttrain-rmse:0.217825+0.000738448\ttest-rmse:0.229982+0.000338589\n",
      "[60]\ttrain-rmse:0.215803+0.000696403\ttest-rmse:0.229821+0.000330749\n",
      "[70]\ttrain-rmse:0.21407+0.000480346\ttest-rmse:0.229861+0.000301982\n",
      "[74]\ttrain-rmse:0.213524+0.000483692\ttest-rmse:0.229886+0.000312402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.216807</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.229865</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.216670</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.229837</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.216476</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.229847</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.229825</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.216040</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.229818</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.215803</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.229821</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.215662</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.229837</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.215509</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.229825</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.215364</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.229776</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.215168</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.229757</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.229786</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.214838</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.229773</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.214594</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.229785</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.214415</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.229843</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.214207</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.229871</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.214070</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.229861</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.213908</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.229848</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.213764</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.229859</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.213629</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.229877</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.213524</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.229886</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "55         0.216807        0.000608        0.229865       0.000400\n",
       "56         0.216670        0.000665        0.229837       0.000399\n",
       "57         0.216476        0.000660        0.229847       0.000392\n",
       "58         0.216309        0.000698        0.229825       0.000358\n",
       "59         0.216040        0.000740        0.229818       0.000357\n",
       "60         0.215803        0.000696        0.229821       0.000331\n",
       "61         0.215662        0.000637        0.229837       0.000346\n",
       "62         0.215509        0.000611        0.229825       0.000338\n",
       "63         0.215364        0.000583        0.229776       0.000361\n",
       "64         0.215168        0.000531        0.229757       0.000340\n",
       "65         0.214992        0.000543        0.229786       0.000344\n",
       "66         0.214838        0.000540        0.229773       0.000290\n",
       "67         0.214594        0.000576        0.229785       0.000255\n",
       "68         0.214415        0.000605        0.229843       0.000237\n",
       "69         0.214207        0.000580        0.229871       0.000293\n",
       "70         0.214070        0.000480        0.229861       0.000302\n",
       "71         0.213908        0.000427        0.229848       0.000299\n",
       "72         0.213764        0.000400        0.229859       0.000301\n",
       "73         0.213629        0.000466        0.229877       0.000347\n",
       "74         0.213524        0.000484        0.229886       0.000312"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvSearch = xgb.cv(param, dtrain, nfold = 3,num_boost_round=75,verbose_eval=10)\n",
    "cvSearch.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of rounds = 64\n",
      "rmse = 0.2297566666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:51: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "bestNR = np.argmax(cvSearch['test-rmse-mean']<eps+min(cvSearch['test-rmse-mean']))\n",
    "bestRMSE = cvSearch.loc[bestNR,'test-rmse-mean']\n",
    "plt.plot(cvSearch['test-rmse-mean'])\n",
    "print('best number of rounds =',bestNR)\n",
    "print('rmse =',bestRMSE) #using bestNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2183176501496354\n"
     ]
    }
   ],
   "source": [
    "modelSearch = xgb.train(param, dtrain,num_boost_round=bestNR)\n",
    "print(RMSE(y,modelSearch.predict(xgb.DMatrix(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24597571526088507\n"
     ]
    }
   ],
   "source": [
    "regSearch = XGBRegressor(objective='reg:squarederror',n_estimators=bestNR)\n",
    "regSearch.fit(X,y)\n",
    "print(RMSE(y,regSearch.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2183176501496354\n"
     ]
    }
   ],
   "source": [
    "regSearch = XGBRegressor(objective='reg:squarederror',n_estimators=bestNR, max_depth=6,\n",
    "                         learning_rate=0.3)\n",
    "regSearch.fit(X,y)\n",
    "print(RMSE(y,regSearch.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost task parameters\n",
    "folds = 3\n",
    "\n",
    "# Parameters grid to search\n",
    "param_test1 = {\n",
    "    'learning_rate':[.3,.15,.05],\n",
    "    'max_depth':[4,5,6],\n",
    "    'n_estimators':np.append(range(30,90,10),bestNR)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=1, objective='reg:squarederror', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.3, 0.15, 0.05], 'max_depth': [4, 5, 6], 'n_estimators': array([30, 40, 50, 60, 70, 80, 64])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = XGBRegressor(objective= 'reg:squarederror',\n",
    "                    nthread=1, seed=0), scoring = 'neg_mean_squared_error',\n",
    "                    param_grid = param_test1, n_jobs=-1,cv=folds,iid=False)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057467 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.057022 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.056879 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 50}\n",
      "0.056693 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 60}\n",
      "0.056519 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 70}\n",
      "0.056394 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 80}\n",
      "0.056650 with:  {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 64}\n",
      "0.056915 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 30}\n",
      "0.056831 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 40}\n",
      "0.057018 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.056915 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 60}\n",
      "0.057051 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 70}\n",
      "0.057162 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 80}\n",
      "0.056894 with:  {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 64}\n",
      "0.056459 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 30}\n",
      "0.056584 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 40}\n",
      "0.056658 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 50}\n",
      "0.056605 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 60}\n",
      "0.056666 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 70}\n",
      "0.056898 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 80}\n",
      "0.056621 with:  {'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 64}\n",
      "0.059977 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.058842 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.058206 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 50}\n",
      "0.057674 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 60}\n",
      "0.057211 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 70}\n",
      "0.057018 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 80}\n",
      "0.057448 with:  {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 64}\n",
      "0.058029 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 30}\n",
      "0.057338 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 40}\n",
      "0.056939 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.056620 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 60}\n",
      "0.056587 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 70}\n",
      "0.056479 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 80}\n",
      "0.056685 with:  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 64}\n",
      "0.056945 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 30}\n",
      "0.056467 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 40}\n",
      "0.056290 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 50}\n",
      "0.056313 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 60}\n",
      "0.056152 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 70}\n",
      "0.056158 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 80}\n",
      "0.056196 with:  {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 64}\n",
      "0.072096 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.067198 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.064117 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 50}\n",
      "0.062263 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 60}\n",
      "0.061335 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 70}\n",
      "0.060683 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 80}\n",
      "0.061823 with:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 64}\n",
      "0.068592 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 30}\n",
      "0.063928 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 40}\n",
      "0.061416 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.060076 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 60}\n",
      "0.059227 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 70}\n",
      "0.058612 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 80}\n",
      "0.059724 with:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 64}\n",
      "0.065874 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 30}\n",
      "0.061844 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 40}\n",
      "0.059741 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50}\n",
      "0.058457 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 60}\n",
      "0.057729 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 70}\n",
      "0.057282 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 80}\n",
      "0.058164 with:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 64}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "for mean,param in zip(grid.cv_results_['mean_test_score'],grid.cv_results_['params']):\n",
    "    print(\"%f with: \" % -mean,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE before tuning: 0.052788\n",
      "Best MSE after tuning: 0.056152 using {'learning_rate': 0.15, 'max_depth': 6, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "print('MSE before tuning: %f' % bestRMSE**2)\n",
    "print(\"Best MSE after tuning: %f using %s\" % (-grid.best_score_,grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "##R^2 from XGBoost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using columns b-e, j to predict i and p\n",
    "##change positions and impressions back to missing_values\n",
    "##try linear\n",
    "#campaign, campaign type, keyword, network, media_cost, and positions to predict click, impression, CTR/Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date-based models (can ignore the next few cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates = df.DATE.unique()\n",
    "#dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select dates\n",
    "#jan416\n",
    "#jan416 = df[\"DATE\"] == \"1/4/2016 0:00\"\n",
    "#filtered_dates = df.loc[jan416]\n",
    "\n",
    "#may1717 = df[\"DATE\"] == \"5/17/2017 0:00\"\n",
    "#filtered_dates = df.loc[may1717]\n",
    "\n",
    "#print(filtered_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan416df = pd.DataFrame(filtered_dates)\n",
    "#may1717df = pd.DataFrame(filtered_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jan416df.ndim\n",
    "#jan416df.size\n",
    "#jan416df.shape\n",
    "#may1717df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#campaign, campaign type, keyword, network, media_cost, and positions to predict click, impression, CTR/Flag\n",
    "\n",
    "#y = jan416df.loc[:,'CTR']\n",
    "#X = jan416df.drop(labels=['DATE','WEEK_OF_YEAR','KEYWORD','Impressions','CPC','Page_Views', 'Clicks', 'Time_On_Site_Total','Visits', 'Visitor_Bounce'], axis=1)\n",
    "\n",
    "#y = may1717df.loc[:,'CTR']\n",
    "#X = may1717df.drop(labels=['DATE','WEEK_OF_YEAR','KEYWORD','Impressions','CPC','Page_Views', 'Clicks', 'Time_On_Site_Total','Visits', 'Visitor_Bounce','CTR'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=clicks\n",
      "XGBoost\n",
      "Test set RMSE of rf: 6.43\n",
      "Train set RMSE of rf: 16.92\n",
      "train RMSE = 4.2467823819922765\n",
      "ADABoost\n",
      "Test set RMSE of rf: 3.80\n",
      "Train set RMSE of rf: 2.29\n",
      "train RMSE = 3.2994110800608234\n"
     ]
    }
   ],
   "source": [
    "##values for y = clicks\n",
    "print('y=clicks')\n",
    "print('XGBoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))\n",
    "\n",
    "print('ADABoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=impressions\n",
      "XGBoost\n",
      "Test set RMSE of rf: 135.74\n",
      "Train set RMSE of rf: 232.26\n",
      "train RMSE = 66.68830060863368\n",
      "ADABoost\n",
      "Test set RMSE of rf: 232.75\n",
      "Train set RMSE of rf: 66.88\n",
      "train RMSE = 52.30926533522398\n"
     ]
    }
   ],
   "source": [
    "##values for y = impressions\n",
    "print('y=impressions')\n",
    "print('XGBoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))\n",
    "\n",
    "print('ADABoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=CTR\n",
      "XGBoost\n",
      "Test set RMSE of rf: 0.30\n",
      "Train set RMSE of rf: 0.24\n",
      "train RMSE = 0.10029652661875361\n",
      "ADABoost\n",
      "Test set RMSE of rf: 0.30\n",
      "Train set RMSE of rf: 0.23\n",
      "train RMSE = 0.2643011975134384\n"
     ]
    }
   ],
   "source": [
    "##values for y = ctr\n",
    "print('y=CTR')\n",
    "print('XGBoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))\n",
    "\n",
    "print('ADABoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=CTR, including Keyword extractions\n",
      "XGBoost\n",
      "Test set RMSE of rf: 0.08\n",
      "Train set RMSE of rf: 0.09\n",
      "train RMSE = 0.004341877226802633\n",
      "ADABoost\n",
      "Test set RMSE of rf: 0.03\n",
      "Train set RMSE of rf: 0.03\n",
      "train RMSE = 0.03526830172729438\n"
     ]
    }
   ],
   "source": [
    "##values for y = CTR,w Keywords\n",
    "print('y=CTR, including Keyword extractions')\n",
    "print('XGBoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))\n",
    "\n",
    "print('ADABoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=CTR, including Keyword extractions\n",
      "XGBoost\n",
      "Test set RMSE of rf: 0.24\n",
      "Train set RMSE of rf: 0.24\n",
      "train RMSE = 0.09270842913216387\n",
      "ADABoost\n",
      "Test set RMSE of rf: 0.29\n",
      "Train set RMSE of rf: 0.29\n",
      "train RMSE = 0.327616666202614\n"
     ]
    }
   ],
   "source": [
    "##values for y = CTR,w Keywords\n",
    "print('y=CTR, including Keyword extractions')\n",
    "print('XGBoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))\n",
    "\n",
    "print('ADABoost')\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = jan416df.loc[:,'CTR']\n",
    "X = jan416df.drop(labels=['DATE','WEEK_OF_YEAR','KEYWORD','Impressions','CPC','Page_Views', 'Clicks', 'Time_On_Site_Total','Visits', 'Visitor_Bounce','CTR'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMPAIGN</th>\n",
       "      <th>CAMPAIGN_TYPE</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>Media_Cost</th>\n",
       "      <th>symptom</th>\n",
       "      <th>asthma</th>\n",
       "      <th>treatment</th>\n",
       "      <th>brand</th>\n",
       "      <th>chemical</th>\n",
       "      <th>payment</th>\n",
       "      <th>age</th>\n",
       "      <th>cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77914</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77915</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77916</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77917</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77918</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CAMPAIGN  CAMPAIGN_TYPE  NETWORK  POSITION  Media_Cost  symptom  \\\n",
       "77914         8              0        0       1.0        2.20        0   \n",
       "77915         8              0        1       1.0        1.57        0   \n",
       "77916        37              1        1       2.0        1.90        0   \n",
       "77917         8              0        1       1.0        4.53        0   \n",
       "77918         8              0        0       1.0        1.00        0   \n",
       "\n",
       "       asthma  treatment  brand  chemical  payment  age  cause  \n",
       "77914       0          3      1         0        0    0      0  \n",
       "77915       0          0      1         0        1    0      0  \n",
       "77916       0          1      3         0        0    0      0  \n",
       "77917       0          0      1         0        0    0      0  \n",
       "77918       0          0      0         6        0    0      0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y.head()\n",
    "#transform response variable by log\n",
    "#most important predictor and word?\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 13)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y,\n",
    "test_size=0.3,\n",
    "random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.0095084]\n",
      " [0.0095084 1.       ]]\n",
      "[[1.        0.0086219]\n",
      " [0.0086219 1.       ]]\n",
      "Test set RMSE of rf: 420.36\n",
      "Train set RMSE of rf: 396.42\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "min_samples_leaf=0.12,\n",
    "random_state=SEED)\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train=rf.predict(X_train)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "#Computer R^2 between y_pred and y_pred_train\n",
    "R2_train = np.corrcoef(y_train, y_pred_train)**2\n",
    "R2_test = np.corrcoef(y_test, y_pred)**2\n",
    "\n",
    "print(R2_train)\n",
    "print(R2_test)\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE = 322.4657379328574\n"
     ]
    }
   ],
   "source": [
    "def RMSE(x,y): \n",
    "    return np.mean((x - y)**2)**0.5\n",
    "rfSearch200 = RandomForestRegressor(n_estimators=200,random_state=0,\n",
    "                                    oob_score=True,n_jobs=-1)#,max_features=6)\n",
    "rfSearch200.fit(X, y)\n",
    "print('train RMSE =',RMSE(y,rfSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y,\n",
    "test_size=0.3,\n",
    "random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostRegressor(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "ada_y_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 454.23\n",
      "Train set RMSE of rf: 446.34\n"
     ]
    }
   ],
   "source": [
    "ada_y_pred_train=ada.predict(X_train)\n",
    "# Evaluate the test set RMSE\n",
    "ada_rmse_test = MSE(y_test, ada_y_pred)**(1/2)\n",
    "ada_rmse_train = MSE(y_train, ada_y_pred_train)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(ada_rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(ada_rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE = 415.36452782856094\n"
     ]
    }
   ],
   "source": [
    "def RMSE(x,y): \n",
    "    return np.mean((x - y)**2)**0.5\n",
    "adaSearch200 = AdaBoostRegressor(base_estimator=dt, n_estimators=180, random_state=1)\n",
    "adaSearch200.fit(X, y)\n",
    "print('train RMSE =',RMSE(y,adaSearch200.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More XGBoost attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# train-test split evaluation of xgboost model\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)\n",
    "# fit model no training data\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.20435664]\n",
      " [0.20435664 1.        ]]\n",
      "[[1.         0.25891023]\n",
      " [0.25891023 1.        ]]\n",
      "Test set RMSE of rf: 350.06\n",
      "Train set RMSE of rf: 361.62\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set labels 'y_pred'\n",
    "#y_pred = rf.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "#Computer R^2 between y_pred and y_pred_train\n",
    "R2_train = np.corrcoef(y_train, y_pred_train)**2\n",
    "R2_test = np.corrcoef(y_test, y_pred)**2\n",
    "\n",
    "print(R2_train)\n",
    "print(R2_test)\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.94523873]\n",
      " [0.94523873 1.        ]]\n",
      "[[1.         0.38299187]\n",
      " [0.38299187 1.        ]]\n",
      "Test set RMSE of rf: 0.25\n",
      "Train set RMSE of rf: 0.09\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:52] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Accuracy: 5.59% (19.04%)\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation evaluation of xgboost model\n",
    "from numpy import loadtxt\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# CV model\n",
    "model = xgboost.XGBRegressor()\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00930614]\n",
      " [0.00930614 1.        ]]\n",
      "[[1.         0.00962729]\n",
      " [0.00962729 1.        ]]\n",
      "Test set RMSE of rf: 395.94\n",
      "Train set RMSE of rf: 400.32\n"
     ]
    }
   ],
   "source": [
    "#XGB rmse\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "min_samples_leaf=0.12,\n",
    "random_state=SEED)\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train=rf.predict(X_train)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "#Computer R^2 between y_pred and y_pred_train\n",
    "R2_train = np.corrcoef(y_train, y_pred_train)**2\n",
    "R2_test = np.corrcoef(y_test, y_pred)**2\n",
    "\n",
    "print(R2_train)\n",
    "print(R2_test)\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another XGBoost Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1, random_state=42)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE is 125.41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"mae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:41:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tTest-mae:0.308903\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:0.274848\n",
      "[2]\tTest-mae:0.25271\n",
      "[3]\tTest-mae:0.237367\n",
      "[4]\tTest-mae:0.226884\n",
      "[5]\tTest-mae:0.220226\n",
      "[6]\tTest-mae:0.215454\n",
      "[7]\tTest-mae:0.212214\n",
      "[8]\tTest-mae:0.209745\n",
      "[9]\tTest-mae:0.207278\n",
      "[10]\tTest-mae:0.206046\n",
      "[11]\tTest-mae:0.205124\n",
      "[12]\tTest-mae:0.2043\n",
      "[13]\tTest-mae:0.20369\n",
      "[14]\tTest-mae:0.203128\n",
      "[15]\tTest-mae:0.20277\n",
      "[16]\tTest-mae:0.202468\n",
      "[17]\tTest-mae:0.20185\n",
      "[18]\tTest-mae:0.201635\n",
      "[19]\tTest-mae:0.201518\n",
      "[20]\tTest-mae:0.201097\n",
      "[21]\tTest-mae:0.200977\n",
      "[22]\tTest-mae:0.200917\n",
      "[23]\tTest-mae:0.2007\n",
      "[24]\tTest-mae:0.20031\n",
      "[25]\tTest-mae:0.199893\n",
      "[26]\tTest-mae:0.199443\n",
      "[27]\tTest-mae:0.199368\n",
      "[28]\tTest-mae:0.199278\n",
      "[29]\tTest-mae:0.199218\n",
      "[30]\tTest-mae:0.199175\n",
      "[31]\tTest-mae:0.198938\n",
      "[32]\tTest-mae:0.198821\n",
      "[33]\tTest-mae:0.198585\n",
      "[34]\tTest-mae:0.198514\n",
      "[35]\tTest-mae:0.198319\n",
      "[36]\tTest-mae:0.198227\n",
      "[37]\tTest-mae:0.19822\n",
      "[38]\tTest-mae:0.198187\n",
      "[39]\tTest-mae:0.198188\n",
      "[40]\tTest-mae:0.198054\n",
      "[41]\tTest-mae:0.198045\n",
      "[42]\tTest-mae:0.198034\n",
      "[43]\tTest-mae:0.197981\n",
      "[44]\tTest-mae:0.197902\n",
      "[45]\tTest-mae:0.197818\n",
      "[46]\tTest-mae:0.19778\n",
      "[47]\tTest-mae:0.197777\n",
      "[48]\tTest-mae:0.197628\n",
      "[49]\tTest-mae:0.197609\n",
      "[50]\tTest-mae:0.197591\n",
      "[51]\tTest-mae:0.197577\n",
      "[52]\tTest-mae:0.197528\n",
      "[53]\tTest-mae:0.197534\n",
      "[54]\tTest-mae:0.197452\n",
      "[55]\tTest-mae:0.197432\n",
      "[56]\tTest-mae:0.197405\n",
      "[57]\tTest-mae:0.197318\n",
      "[58]\tTest-mae:0.197242\n",
      "[59]\tTest-mae:0.197181\n",
      "[60]\tTest-mae:0.197112\n",
      "[61]\tTest-mae:0.197123\n",
      "[62]\tTest-mae:0.1971\n",
      "[63]\tTest-mae:0.197058\n",
      "[64]\tTest-mae:0.197041\n",
      "[65]\tTest-mae:0.197026\n",
      "[66]\tTest-mae:0.197019\n",
      "[67]\tTest-mae:0.19699\n",
      "[68]\tTest-mae:0.196973\n",
      "[69]\tTest-mae:0.19692\n",
      "[70]\tTest-mae:0.196886\n",
      "[71]\tTest-mae:0.196885\n",
      "[72]\tTest-mae:0.196839\n",
      "[73]\tTest-mae:0.196838\n",
      "[74]\tTest-mae:0.196811\n",
      "[75]\tTest-mae:0.196805\n",
      "[76]\tTest-mae:0.196784\n",
      "[77]\tTest-mae:0.196711\n",
      "[78]\tTest-mae:0.196699\n",
      "[79]\tTest-mae:0.196701\n",
      "[80]\tTest-mae:0.19668\n",
      "[81]\tTest-mae:0.19667\n",
      "[82]\tTest-mae:0.196661\n",
      "[83]\tTest-mae:0.196653\n",
      "[84]\tTest-mae:0.196613\n",
      "[85]\tTest-mae:0.196564\n",
      "[86]\tTest-mae:0.196539\n",
      "[87]\tTest-mae:0.196535\n",
      "[88]\tTest-mae:0.196518\n",
      "[89]\tTest-mae:0.196508\n",
      "[90]\tTest-mae:0.196525\n",
      "[91]\tTest-mae:0.19651\n",
      "[92]\tTest-mae:0.196521\n",
      "[93]\tTest-mae:0.196509\n",
      "[94]\tTest-mae:0.196508\n",
      "[95]\tTest-mae:0.196492\n",
      "[96]\tTest-mae:0.196482\n",
      "[97]\tTest-mae:0.196471\n",
      "[98]\tTest-mae:0.196418\n",
      "[99]\tTest-mae:0.196409\n",
      "[100]\tTest-mae:0.196407\n",
      "[101]\tTest-mae:0.196406\n",
      "[102]\tTest-mae:0.196387\n",
      "[103]\tTest-mae:0.196374\n",
      "[104]\tTest-mae:0.196349\n",
      "[105]\tTest-mae:0.196326\n",
      "[106]\tTest-mae:0.196316\n",
      "[107]\tTest-mae:0.196306\n",
      "[108]\tTest-mae:0.196297\n",
      "[109]\tTest-mae:0.196295\n",
      "[110]\tTest-mae:0.196293\n",
      "[111]\tTest-mae:0.196284\n",
      "[112]\tTest-mae:0.196282\n",
      "[113]\tTest-mae:0.196286\n",
      "[114]\tTest-mae:0.196287\n",
      "[115]\tTest-mae:0.196277\n",
      "[116]\tTest-mae:0.196267\n",
      "[117]\tTest-mae:0.196266\n",
      "[118]\tTest-mae:0.196264\n",
      "[119]\tTest-mae:0.196258\n",
      "[120]\tTest-mae:0.196241\n",
      "[121]\tTest-mae:0.196249\n",
      "[122]\tTest-mae:0.196234\n",
      "[123]\tTest-mae:0.196244\n",
      "[124]\tTest-mae:0.196239\n",
      "[125]\tTest-mae:0.196247\n",
      "[126]\tTest-mae:0.196231\n",
      "[127]\tTest-mae:0.196225\n",
      "[128]\tTest-mae:0.196223\n",
      "[129]\tTest-mae:0.196217\n",
      "[130]\tTest-mae:0.19621\n",
      "[131]\tTest-mae:0.196209\n",
      "[132]\tTest-mae:0.196209\n",
      "[133]\tTest-mae:0.196202\n",
      "[134]\tTest-mae:0.196198\n",
      "[135]\tTest-mae:0.196198\n",
      "[136]\tTest-mae:0.196199\n",
      "[137]\tTest-mae:0.196199\n",
      "[138]\tTest-mae:0.196161\n",
      "[139]\tTest-mae:0.196154\n",
      "[140]\tTest-mae:0.196148\n",
      "[141]\tTest-mae:0.196151\n",
      "[142]\tTest-mae:0.196144\n",
      "[143]\tTest-mae:0.196138\n",
      "[144]\tTest-mae:0.196139\n",
      "[145]\tTest-mae:0.196136\n",
      "[146]\tTest-mae:0.196129\n",
      "[147]\tTest-mae:0.196127\n",
      "[148]\tTest-mae:0.196124\n",
      "[149]\tTest-mae:0.19612\n",
      "[150]\tTest-mae:0.196113\n",
      "[151]\tTest-mae:0.196117\n",
      "[152]\tTest-mae:0.196117\n",
      "[153]\tTest-mae:0.196123\n",
      "[154]\tTest-mae:0.196122\n",
      "[155]\tTest-mae:0.196114\n",
      "[156]\tTest-mae:0.196097\n",
      "[157]\tTest-mae:0.196107\n",
      "[158]\tTest-mae:0.196105\n",
      "[159]\tTest-mae:0.19609\n",
      "[160]\tTest-mae:0.196091\n",
      "[161]\tTest-mae:0.196092\n",
      "[162]\tTest-mae:0.196089\n",
      "[163]\tTest-mae:0.196092\n",
      "[164]\tTest-mae:0.196088\n",
      "[165]\tTest-mae:0.19609\n",
      "[166]\tTest-mae:0.196092\n",
      "[167]\tTest-mae:0.196093\n",
      "[168]\tTest-mae:0.196092\n",
      "[169]\tTest-mae:0.196094\n",
      "[170]\tTest-mae:0.196095\n",
      "[171]\tTest-mae:0.196102\n",
      "[172]\tTest-mae:0.196094\n",
      "[173]\tTest-mae:0.196093\n",
      "[174]\tTest-mae:0.196093\n",
      "Stopping. Best iteration:\n",
      "[164]\tTest-mae:0.196088\n",
      "\n",
      "Best MAE: 0.20 with 165 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:41:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:41:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:41:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:41:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:41:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.305540</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.305658</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272107</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.272341</td>\n",
       "      <td>0.000864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250421</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.250786</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235340</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.235759</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225413</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.218527</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.219111</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.213673</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.214371</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.210113</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.210841</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.207561</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.208352</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.205623</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.206469</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.204229</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.205118</td>\n",
       "      <td>0.001253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.202868</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.203813</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.201703</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.200935</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.202002</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.200229</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.199719</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.200883</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.199425</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.200638</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.199004</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.200262</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.198723</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.198389</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.199716</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.198093</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.199423</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.197878</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.199239</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.197636</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.199029</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.198868</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.197220</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.198647</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.197018</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.198495</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.196838</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.196583</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.198112</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.196414</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.198002</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.196230</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.197870</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.191530</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.191528</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194422</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.191527</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194424</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.191525</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.191523</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194420</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.191520</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194419</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.191516</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194417</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.191515</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.194414</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.191512</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194412</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.191509</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.194412</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.191507</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.194411</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.191505</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.194410</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.191501</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.194407</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.191501</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194406</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.191497</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.194404</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.191495</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.194404</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.191493</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.194404</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.191486</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.191483</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.194399</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.191478</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.194397</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.191475</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.191473</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.191468</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.191467</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.191464</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.194394</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.191463</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.194395</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.191462</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.194394</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.191456</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.194390</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.191450</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.194382</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.191446</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.194381</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0          0.305540       0.000266       0.305658      0.000905\n",
       "1          0.272107       0.000381       0.272341      0.000864\n",
       "2          0.250421       0.000472       0.250786      0.000894\n",
       "3          0.235340       0.000615       0.235759      0.000984\n",
       "4          0.225413       0.000574       0.225926      0.001076\n",
       "5          0.218527       0.000704       0.219111      0.000961\n",
       "6          0.213673       0.000611       0.214371      0.001084\n",
       "7          0.210113       0.000601       0.210841      0.001029\n",
       "8          0.207561       0.000504       0.208352      0.001180\n",
       "9          0.205623       0.000539       0.206469      0.001149\n",
       "10         0.204229       0.000439       0.205118      0.001253\n",
       "11         0.202868       0.000495       0.203813      0.001164\n",
       "12         0.201703       0.000561       0.202688      0.001098\n",
       "13         0.200935       0.000553       0.202002      0.001046\n",
       "14         0.200229       0.000370       0.201362      0.001180\n",
       "15         0.199719       0.000473       0.200883      0.001089\n",
       "16         0.199425       0.000457       0.200638      0.001153\n",
       "17         0.199004       0.000468       0.200262      0.001065\n",
       "18         0.198723       0.000438       0.200023      0.001091\n",
       "19         0.198389       0.000440       0.199716      0.001127\n",
       "20         0.198093       0.000400       0.199423      0.001095\n",
       "21         0.197878       0.000450       0.199239      0.001037\n",
       "22         0.197636       0.000431       0.199029      0.001030\n",
       "23         0.197452       0.000437       0.198868      0.001010\n",
       "24         0.197220       0.000411       0.198647      0.001013\n",
       "25         0.197018       0.000416       0.198495      0.000979\n",
       "26         0.196838       0.000521       0.198338      0.000898\n",
       "27         0.196583       0.000594       0.198112      0.000817\n",
       "28         0.196414       0.000601       0.198002      0.000785\n",
       "29         0.196230       0.000567       0.197870      0.000813\n",
       "..              ...            ...            ...           ...\n",
       "197        0.191530       0.000458       0.194421      0.000989\n",
       "198        0.191528       0.000457       0.194422      0.000990\n",
       "199        0.191527       0.000456       0.194424      0.000990\n",
       "200        0.191525       0.000457       0.194421      0.000990\n",
       "201        0.191523       0.000456       0.194420      0.000992\n",
       "202        0.191520       0.000456       0.194419      0.000992\n",
       "203        0.191516       0.000457       0.194417      0.000990\n",
       "204        0.191515       0.000458       0.194414      0.000989\n",
       "205        0.191512       0.000457       0.194412      0.000993\n",
       "206        0.191509       0.000459       0.194412      0.000993\n",
       "207        0.191507       0.000460       0.194411      0.000991\n",
       "208        0.191505       0.000459       0.194410      0.000991\n",
       "209        0.191501       0.000458       0.194407      0.000993\n",
       "210        0.191501       0.000456       0.194406      0.000992\n",
       "211        0.191497       0.000458       0.194404      0.000991\n",
       "212        0.191495       0.000459       0.194404      0.000991\n",
       "213        0.191493       0.000459       0.194404      0.000991\n",
       "214        0.191486       0.000464       0.194400      0.000987\n",
       "215        0.191483       0.000463       0.194399      0.000985\n",
       "216        0.191478       0.000462       0.194397      0.000984\n",
       "217        0.191475       0.000461       0.194396      0.000984\n",
       "218        0.191473       0.000457       0.194398      0.000986\n",
       "219        0.191468       0.000456       0.194396      0.000986\n",
       "220        0.191467       0.000457       0.194396      0.000986\n",
       "221        0.191464       0.000455       0.194394      0.000984\n",
       "222        0.191463       0.000455       0.194395      0.000984\n",
       "223        0.191462       0.000456       0.194394      0.000984\n",
       "224        0.191456       0.000451       0.194390      0.000987\n",
       "225        0.191450       0.000446       0.194382      0.000995\n",
       "226        0.191446       0.000445       0.194381      0.000997\n",
       "\n",
       "[227 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1943806"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-mae-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "[11:43:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.1943606 for 199 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "[11:45:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:45:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:45:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:45:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:45:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.194387 for 218 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "[11:47:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:47:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:47:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:47:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:47:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1944196 for 166 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "[11:48:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:48:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:48:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:48:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:48:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19428360000000003 for 236 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "[11:50:52] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:50:52] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:50:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:50:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:50:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.194331 for 253 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "[11:53:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:53:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:53:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:53:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:53:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19444299999999998 for 114 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "[11:54:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:54:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:54:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:54:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:54:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1942948 for 207 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "[11:56:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:56:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:56:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:56:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:56:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1943838 for 154 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "[11:57:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:57:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:57:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:57:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:57:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1943852 for 120 rounds\n",
      "Best params: 10, 5, MAE: 0.19428360000000003\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "[12:01:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:01:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:01:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:01:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:01:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.19428360000000003 for 236 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "[12:03:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:03:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:03:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:03:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:03:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19431199999999998 for 236 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "[12:05:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:05:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:05:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:05:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:05:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19432580000000002 for 233 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "[12:06:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:06:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:06:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:06:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:06:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.194288 for 349 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "[12:09:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:09:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:09:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:09:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:09:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19432999999999997 for 93 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "[12:10:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1943824 for 92 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "[12:11:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:11:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:11:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:11:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:11:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19441060000000002 for 92 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "[12:12:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:12:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:12:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:12:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:12:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1944096 for 128 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "[12:13:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1945686 for 44 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "[12:13:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1945058 for 67 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "[12:14:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:14:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1945538 for 76 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "[12:15:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:15:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:15:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:15:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:15:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1945084 for 104 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "[12:16:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:16:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:16:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:16:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:16:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.19459939999999998 for 42 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "[12:17:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1944204 for 70 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "[12:17:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.1948022 for 42 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "[12:18:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\tMAE 0.194683 for 70 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.19428360000000003\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1\n",
    "params['colsample_bytree'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "[12:28:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:28:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:28:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:28:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:28:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 2min 6s\n",
      "CV with eta=0.2\n",
      "[12:30:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:30:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:30:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:30:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:30:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 2min 42s\n",
      "CV with eta=0.1\n",
      "[12:33:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 5min 21s\n",
      "CV with eta=0.05\n",
      "[12:38:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:38:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:38:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:38:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:38:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 3min 51s\n",
      "CV with eta=0.01\n",
      "[12:42:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:42:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:42:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:42:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:42:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 8min 49s\n",
      "CV with eta=0.005\n",
      "[12:51:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Wall time: 9min 20s\n",
      "\tMAE 0.1972108 for 998 rounds\n",
      "\n",
      "Best params: 0.005, MAE: 0.1972108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics=['mae'], early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "mean_mae = cv_results['test-mae-mean'].min()\n",
    "boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "if mean_mae < min_mae:\n",
    "    min_mae = mean_mae\n",
    "    best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.01,\n",
       " 'eval_metric': 'mae',\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 5,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final parameters dict\n",
    "params \n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.01,\n",
    " 'eval_metric': 'mae',\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 5,\n",
    " 'objective': 'reg:squarederror',\n",
    " 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tTest-mae:0.357788\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:0.356929\n",
      "[2]\tTest-mae:0.356076\n",
      "[3]\tTest-mae:0.355226\n",
      "[4]\tTest-mae:0.354381\n",
      "[5]\tTest-mae:0.35354\n",
      "[6]\tTest-mae:0.352703\n",
      "[7]\tTest-mae:0.351869\n",
      "[8]\tTest-mae:0.351039\n",
      "[9]\tTest-mae:0.350215\n",
      "[10]\tTest-mae:0.349392\n",
      "[11]\tTest-mae:0.348575\n",
      "[12]\tTest-mae:0.347765\n",
      "[13]\tTest-mae:0.346955\n",
      "[14]\tTest-mae:0.34615\n",
      "[15]\tTest-mae:0.345348\n",
      "[16]\tTest-mae:0.344553\n",
      "[17]\tTest-mae:0.343758\n",
      "[18]\tTest-mae:0.34297\n",
      "[19]\tTest-mae:0.342184\n",
      "[20]\tTest-mae:0.341402\n",
      "[21]\tTest-mae:0.340625\n",
      "[22]\tTest-mae:0.339851\n",
      "[23]\tTest-mae:0.339082\n",
      "[24]\tTest-mae:0.338317\n",
      "[25]\tTest-mae:0.337556\n",
      "[26]\tTest-mae:0.336797\n",
      "[27]\tTest-mae:0.336043\n",
      "[28]\tTest-mae:0.335293\n",
      "[29]\tTest-mae:0.334546\n",
      "[30]\tTest-mae:0.333802\n",
      "[31]\tTest-mae:0.333062\n",
      "[32]\tTest-mae:0.332326\n",
      "[33]\tTest-mae:0.331594\n",
      "[34]\tTest-mae:0.330867\n",
      "[35]\tTest-mae:0.330142\n",
      "[36]\tTest-mae:0.32942\n",
      "[37]\tTest-mae:0.328703\n",
      "[38]\tTest-mae:0.32799\n",
      "[39]\tTest-mae:0.327278\n",
      "[40]\tTest-mae:0.326572\n",
      "[41]\tTest-mae:0.325868\n",
      "[42]\tTest-mae:0.325168\n",
      "[43]\tTest-mae:0.324472\n",
      "[44]\tTest-mae:0.32378\n",
      "[45]\tTest-mae:0.32309\n",
      "[46]\tTest-mae:0.322405\n",
      "[47]\tTest-mae:0.321723\n",
      "[48]\tTest-mae:0.321044\n",
      "[49]\tTest-mae:0.320368\n",
      "[50]\tTest-mae:0.319699\n",
      "[51]\tTest-mae:0.31903\n",
      "[52]\tTest-mae:0.318365\n",
      "[53]\tTest-mae:0.317704\n",
      "[54]\tTest-mae:0.317046\n",
      "[55]\tTest-mae:0.316389\n",
      "[56]\tTest-mae:0.31574\n",
      "[57]\tTest-mae:0.315093\n",
      "[58]\tTest-mae:0.314447\n",
      "[59]\tTest-mae:0.313806\n",
      "[60]\tTest-mae:0.31317\n",
      "[61]\tTest-mae:0.312536\n",
      "[62]\tTest-mae:0.311903\n",
      "[63]\tTest-mae:0.311275\n",
      "[64]\tTest-mae:0.310652\n",
      "[65]\tTest-mae:0.310028\n",
      "[66]\tTest-mae:0.309411\n",
      "[67]\tTest-mae:0.308797\n",
      "[68]\tTest-mae:0.308185\n",
      "[69]\tTest-mae:0.307578\n",
      "[70]\tTest-mae:0.306972\n",
      "[71]\tTest-mae:0.30637\n",
      "[72]\tTest-mae:0.305773\n",
      "[73]\tTest-mae:0.305179\n",
      "[74]\tTest-mae:0.304587\n",
      "[75]\tTest-mae:0.303998\n",
      "[76]\tTest-mae:0.303415\n",
      "[77]\tTest-mae:0.302834\n",
      "[78]\tTest-mae:0.302253\n",
      "[79]\tTest-mae:0.301678\n",
      "[80]\tTest-mae:0.301105\n",
      "[81]\tTest-mae:0.300535\n",
      "[82]\tTest-mae:0.29997\n",
      "[83]\tTest-mae:0.299408\n",
      "[84]\tTest-mae:0.298847\n",
      "[85]\tTest-mae:0.29829\n",
      "[86]\tTest-mae:0.297738\n",
      "[87]\tTest-mae:0.29719\n",
      "[88]\tTest-mae:0.296641\n",
      "[89]\tTest-mae:0.296097\n",
      "[90]\tTest-mae:0.295556\n",
      "[91]\tTest-mae:0.295018\n",
      "[92]\tTest-mae:0.294482\n",
      "[93]\tTest-mae:0.293947\n",
      "[94]\tTest-mae:0.293415\n",
      "[95]\tTest-mae:0.292888\n",
      "[96]\tTest-mae:0.292364\n",
      "[97]\tTest-mae:0.291842\n",
      "[98]\tTest-mae:0.291324\n",
      "[99]\tTest-mae:0.290809\n",
      "[100]\tTest-mae:0.290293\n",
      "[101]\tTest-mae:0.289782\n",
      "[102]\tTest-mae:0.289275\n",
      "[103]\tTest-mae:0.288769\n",
      "[104]\tTest-mae:0.288269\n",
      "[105]\tTest-mae:0.287767\n",
      "[106]\tTest-mae:0.287271\n",
      "[107]\tTest-mae:0.286774\n",
      "[108]\tTest-mae:0.286282\n",
      "[109]\tTest-mae:0.28579\n",
      "[110]\tTest-mae:0.285303\n",
      "[111]\tTest-mae:0.284819\n",
      "[112]\tTest-mae:0.284334\n",
      "[113]\tTest-mae:0.283855\n",
      "[114]\tTest-mae:0.28338\n",
      "[115]\tTest-mae:0.282909\n",
      "[116]\tTest-mae:0.282437\n",
      "[117]\tTest-mae:0.281967\n",
      "[118]\tTest-mae:0.281501\n",
      "[119]\tTest-mae:0.281039\n",
      "[120]\tTest-mae:0.280577\n",
      "[121]\tTest-mae:0.280117\n",
      "[122]\tTest-mae:0.279662\n",
      "[123]\tTest-mae:0.279209\n",
      "[124]\tTest-mae:0.278754\n",
      "[125]\tTest-mae:0.278302\n",
      "[126]\tTest-mae:0.277853\n",
      "[127]\tTest-mae:0.277408\n",
      "[128]\tTest-mae:0.276971\n",
      "[129]\tTest-mae:0.276532\n",
      "[130]\tTest-mae:0.276095\n",
      "[131]\tTest-mae:0.275662\n",
      "[132]\tTest-mae:0.275232\n",
      "[133]\tTest-mae:0.274806\n",
      "[134]\tTest-mae:0.274384\n",
      "[135]\tTest-mae:0.273963\n",
      "[136]\tTest-mae:0.273546\n",
      "[137]\tTest-mae:0.273129\n",
      "[138]\tTest-mae:0.272715\n",
      "[139]\tTest-mae:0.272304\n",
      "[140]\tTest-mae:0.271894\n",
      "[141]\tTest-mae:0.271488\n",
      "[142]\tTest-mae:0.271083\n",
      "[143]\tTest-mae:0.270683\n",
      "[144]\tTest-mae:0.270284\n",
      "[145]\tTest-mae:0.269887\n",
      "[146]\tTest-mae:0.269491\n",
      "[147]\tTest-mae:0.269098\n",
      "[148]\tTest-mae:0.268708\n",
      "[149]\tTest-mae:0.268321\n",
      "[150]\tTest-mae:0.267937\n",
      "[151]\tTest-mae:0.267552\n",
      "[152]\tTest-mae:0.267173\n",
      "[153]\tTest-mae:0.26679\n",
      "[154]\tTest-mae:0.266413\n",
      "[155]\tTest-mae:0.266036\n",
      "[156]\tTest-mae:0.265662\n",
      "[157]\tTest-mae:0.26529\n",
      "[158]\tTest-mae:0.264921\n",
      "[159]\tTest-mae:0.264551\n",
      "[160]\tTest-mae:0.264186\n",
      "[161]\tTest-mae:0.263822\n",
      "[162]\tTest-mae:0.263461\n",
      "[163]\tTest-mae:0.2631\n",
      "[164]\tTest-mae:0.262744\n",
      "[165]\tTest-mae:0.262388\n",
      "[166]\tTest-mae:0.262037\n",
      "[167]\tTest-mae:0.261686\n",
      "[168]\tTest-mae:0.261337\n",
      "[169]\tTest-mae:0.260995\n",
      "[170]\tTest-mae:0.260653\n",
      "[171]\tTest-mae:0.260319\n",
      "[172]\tTest-mae:0.259987\n",
      "[173]\tTest-mae:0.259657\n",
      "[174]\tTest-mae:0.259327\n",
      "[175]\tTest-mae:0.259002\n",
      "[176]\tTest-mae:0.258675\n",
      "[177]\tTest-mae:0.258355\n",
      "[178]\tTest-mae:0.258038\n",
      "[179]\tTest-mae:0.257719\n",
      "[180]\tTest-mae:0.257405\n",
      "[181]\tTest-mae:0.257092\n",
      "[182]\tTest-mae:0.256778\n",
      "[183]\tTest-mae:0.256463\n",
      "[184]\tTest-mae:0.256154\n",
      "[185]\tTest-mae:0.255843\n",
      "[186]\tTest-mae:0.255534\n",
      "[187]\tTest-mae:0.255228\n",
      "[188]\tTest-mae:0.254924\n",
      "[189]\tTest-mae:0.254622\n",
      "[190]\tTest-mae:0.254319\n",
      "[191]\tTest-mae:0.25402\n",
      "[192]\tTest-mae:0.253721\n",
      "[193]\tTest-mae:0.253425\n",
      "[194]\tTest-mae:0.253135\n",
      "[195]\tTest-mae:0.252848\n",
      "[196]\tTest-mae:0.252558\n",
      "[197]\tTest-mae:0.252275\n",
      "[198]\tTest-mae:0.25199\n",
      "[199]\tTest-mae:0.251708\n",
      "[200]\tTest-mae:0.251425\n",
      "[201]\tTest-mae:0.251145\n",
      "[202]\tTest-mae:0.250867\n",
      "[203]\tTest-mae:0.25059\n",
      "[204]\tTest-mae:0.250313\n",
      "[205]\tTest-mae:0.25004\n",
      "[206]\tTest-mae:0.249767\n",
      "[207]\tTest-mae:0.249495\n",
      "[208]\tTest-mae:0.249225\n",
      "[209]\tTest-mae:0.248957\n",
      "[210]\tTest-mae:0.248689\n",
      "[211]\tTest-mae:0.248422\n",
      "[212]\tTest-mae:0.248159\n",
      "[213]\tTest-mae:0.247896\n",
      "[214]\tTest-mae:0.247635\n",
      "[215]\tTest-mae:0.247375\n",
      "[216]\tTest-mae:0.247117\n",
      "[217]\tTest-mae:0.24686\n",
      "[218]\tTest-mae:0.246604\n",
      "[219]\tTest-mae:0.246351\n",
      "[220]\tTest-mae:0.2461\n",
      "[221]\tTest-mae:0.245847\n",
      "[222]\tTest-mae:0.245598\n",
      "[223]\tTest-mae:0.245348\n",
      "[224]\tTest-mae:0.245101\n",
      "[225]\tTest-mae:0.244854\n",
      "[226]\tTest-mae:0.24461\n",
      "[227]\tTest-mae:0.244367\n",
      "[228]\tTest-mae:0.244125\n",
      "[229]\tTest-mae:0.243885\n",
      "[230]\tTest-mae:0.243645\n",
      "[231]\tTest-mae:0.243407\n",
      "[232]\tTest-mae:0.243165\n",
      "[233]\tTest-mae:0.242932\n",
      "[234]\tTest-mae:0.242697\n",
      "[235]\tTest-mae:0.242462\n",
      "[236]\tTest-mae:0.242231\n",
      "[237]\tTest-mae:0.241998\n",
      "[238]\tTest-mae:0.241767\n",
      "[239]\tTest-mae:0.241538\n",
      "[240]\tTest-mae:0.241312\n",
      "[241]\tTest-mae:0.241086\n",
      "[242]\tTest-mae:0.240862\n",
      "[243]\tTest-mae:0.240638\n",
      "[244]\tTest-mae:0.240416\n",
      "[245]\tTest-mae:0.240195\n",
      "[246]\tTest-mae:0.239977\n",
      "[247]\tTest-mae:0.239758\n",
      "[248]\tTest-mae:0.239544\n",
      "[249]\tTest-mae:0.239329\n",
      "[250]\tTest-mae:0.239115\n",
      "[251]\tTest-mae:0.238903\n",
      "[252]\tTest-mae:0.238691\n",
      "[253]\tTest-mae:0.238481\n",
      "[254]\tTest-mae:0.238273\n",
      "[255]\tTest-mae:0.238065\n",
      "[256]\tTest-mae:0.237856\n",
      "[257]\tTest-mae:0.237651\n",
      "[258]\tTest-mae:0.237446\n",
      "[259]\tTest-mae:0.237243\n",
      "[260]\tTest-mae:0.237041\n",
      "[261]\tTest-mae:0.236837\n",
      "[262]\tTest-mae:0.236637\n",
      "[263]\tTest-mae:0.236438\n",
      "[264]\tTest-mae:0.236239\n",
      "[265]\tTest-mae:0.236045\n",
      "[266]\tTest-mae:0.235848\n",
      "[267]\tTest-mae:0.235655\n",
      "[268]\tTest-mae:0.235462\n",
      "[269]\tTest-mae:0.235272\n",
      "[270]\tTest-mae:0.235082\n",
      "[271]\tTest-mae:0.234892\n",
      "[272]\tTest-mae:0.234702\n",
      "[273]\tTest-mae:0.234515\n",
      "[274]\tTest-mae:0.234329\n",
      "[275]\tTest-mae:0.234145\n",
      "[276]\tTest-mae:0.233959\n",
      "[277]\tTest-mae:0.233777\n",
      "[278]\tTest-mae:0.233591\n",
      "[279]\tTest-mae:0.23341\n",
      "[280]\tTest-mae:0.233232\n",
      "[281]\tTest-mae:0.233053\n",
      "[282]\tTest-mae:0.232878\n",
      "[283]\tTest-mae:0.232701\n",
      "[284]\tTest-mae:0.232528\n",
      "[285]\tTest-mae:0.232351\n",
      "[286]\tTest-mae:0.23218\n",
      "[287]\tTest-mae:0.232007\n",
      "[288]\tTest-mae:0.231832\n",
      "[289]\tTest-mae:0.231662\n",
      "[290]\tTest-mae:0.231494\n",
      "[291]\tTest-mae:0.231323\n",
      "[292]\tTest-mae:0.231156\n",
      "[293]\tTest-mae:0.230986\n",
      "[294]\tTest-mae:0.230819\n",
      "[295]\tTest-mae:0.230653\n",
      "[296]\tTest-mae:0.230485\n",
      "[297]\tTest-mae:0.230321\n",
      "[298]\tTest-mae:0.230159\n",
      "[299]\tTest-mae:0.229998\n",
      "[300]\tTest-mae:0.229836\n",
      "[301]\tTest-mae:0.229676\n",
      "[302]\tTest-mae:0.229518\n",
      "[303]\tTest-mae:0.229358\n",
      "[304]\tTest-mae:0.229204\n",
      "[305]\tTest-mae:0.229045\n",
      "[306]\tTest-mae:0.22889\n",
      "[307]\tTest-mae:0.228736\n",
      "[308]\tTest-mae:0.228575\n",
      "[309]\tTest-mae:0.228424\n",
      "[310]\tTest-mae:0.228272\n",
      "[311]\tTest-mae:0.228122\n",
      "[312]\tTest-mae:0.22797\n",
      "[313]\tTest-mae:0.22782\n",
      "[314]\tTest-mae:0.227673\n",
      "[315]\tTest-mae:0.227524\n",
      "[316]\tTest-mae:0.227371\n",
      "[317]\tTest-mae:0.227225\n",
      "[318]\tTest-mae:0.227077\n",
      "[319]\tTest-mae:0.226934\n",
      "[320]\tTest-mae:0.22679\n",
      "[321]\tTest-mae:0.226647\n",
      "[322]\tTest-mae:0.226504\n",
      "[323]\tTest-mae:0.226362\n",
      "[324]\tTest-mae:0.22622\n",
      "[325]\tTest-mae:0.226078\n",
      "[326]\tTest-mae:0.22594\n",
      "[327]\tTest-mae:0.225802\n",
      "[328]\tTest-mae:0.225663\n",
      "[329]\tTest-mae:0.225524\n",
      "[330]\tTest-mae:0.225382\n",
      "[331]\tTest-mae:0.225245\n",
      "[332]\tTest-mae:0.225112\n",
      "[333]\tTest-mae:0.224974\n",
      "[334]\tTest-mae:0.224835\n",
      "[335]\tTest-mae:0.224703\n",
      "[336]\tTest-mae:0.22457\n",
      "[337]\tTest-mae:0.224439\n",
      "[338]\tTest-mae:0.224306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339]\tTest-mae:0.224169\n",
      "[340]\tTest-mae:0.22404\n",
      "[341]\tTest-mae:0.223903\n",
      "[342]\tTest-mae:0.223774\n",
      "[343]\tTest-mae:0.223641\n",
      "[344]\tTest-mae:0.223512\n",
      "[345]\tTest-mae:0.223381\n",
      "[346]\tTest-mae:0.22325\n",
      "[347]\tTest-mae:0.223123\n",
      "[348]\tTest-mae:0.222994\n",
      "[349]\tTest-mae:0.222868\n",
      "[350]\tTest-mae:0.222743\n",
      "[351]\tTest-mae:0.222617\n",
      "[352]\tTest-mae:0.222493\n",
      "[353]\tTest-mae:0.22237\n",
      "[354]\tTest-mae:0.222245\n",
      "[355]\tTest-mae:0.222124\n",
      "[356]\tTest-mae:0.222005\n",
      "[357]\tTest-mae:0.221882\n",
      "[358]\tTest-mae:0.221762\n",
      "[359]\tTest-mae:0.221645\n",
      "[360]\tTest-mae:0.221525\n",
      "[361]\tTest-mae:0.221405\n",
      "[362]\tTest-mae:0.221289\n",
      "[363]\tTest-mae:0.221172\n",
      "[364]\tTest-mae:0.221059\n",
      "[365]\tTest-mae:0.220942\n",
      "[366]\tTest-mae:0.220831\n",
      "[367]\tTest-mae:0.220715\n",
      "[368]\tTest-mae:0.220603\n",
      "[369]\tTest-mae:0.220488\n",
      "[370]\tTest-mae:0.220378\n",
      "[371]\tTest-mae:0.220269\n",
      "[372]\tTest-mae:0.220157\n",
      "[373]\tTest-mae:0.220048\n",
      "[374]\tTest-mae:0.219941\n",
      "[375]\tTest-mae:0.219831\n",
      "[376]\tTest-mae:0.219725\n",
      "[377]\tTest-mae:0.21962\n",
      "[378]\tTest-mae:0.219512\n",
      "[379]\tTest-mae:0.219404\n",
      "[380]\tTest-mae:0.219302\n",
      "[381]\tTest-mae:0.2192\n",
      "[382]\tTest-mae:0.219095\n",
      "[383]\tTest-mae:0.218988\n",
      "[384]\tTest-mae:0.218884\n",
      "[385]\tTest-mae:0.218782\n",
      "[386]\tTest-mae:0.218679\n",
      "[387]\tTest-mae:0.218576\n",
      "[388]\tTest-mae:0.218476\n",
      "[389]\tTest-mae:0.218374\n",
      "[390]\tTest-mae:0.218274\n",
      "[391]\tTest-mae:0.218174\n",
      "[392]\tTest-mae:0.218075\n",
      "[393]\tTest-mae:0.217979\n",
      "[394]\tTest-mae:0.217883\n",
      "[395]\tTest-mae:0.217789\n",
      "[396]\tTest-mae:0.217696\n",
      "[397]\tTest-mae:0.2176\n",
      "[398]\tTest-mae:0.217503\n",
      "[399]\tTest-mae:0.217409\n",
      "[400]\tTest-mae:0.217317\n",
      "[401]\tTest-mae:0.217228\n",
      "[402]\tTest-mae:0.217136\n",
      "[403]\tTest-mae:0.217043\n",
      "[404]\tTest-mae:0.21695\n",
      "[405]\tTest-mae:0.216858\n",
      "[406]\tTest-mae:0.216759\n",
      "[407]\tTest-mae:0.216665\n",
      "[408]\tTest-mae:0.216574\n",
      "[409]\tTest-mae:0.216477\n",
      "[410]\tTest-mae:0.216384\n",
      "[411]\tTest-mae:0.216288\n",
      "[412]\tTest-mae:0.216199\n",
      "[413]\tTest-mae:0.216104\n",
      "[414]\tTest-mae:0.216016\n",
      "[415]\tTest-mae:0.215925\n",
      "[416]\tTest-mae:0.215831\n",
      "[417]\tTest-mae:0.215746\n",
      "[418]\tTest-mae:0.215653\n",
      "[419]\tTest-mae:0.215569\n",
      "[420]\tTest-mae:0.215485\n",
      "[421]\tTest-mae:0.215395\n",
      "[422]\tTest-mae:0.215312\n",
      "[423]\tTest-mae:0.215221\n",
      "[424]\tTest-mae:0.215141\n",
      "[425]\tTest-mae:0.21505\n",
      "[426]\tTest-mae:0.214971\n",
      "[427]\tTest-mae:0.214891\n",
      "[428]\tTest-mae:0.214805\n",
      "[429]\tTest-mae:0.214718\n",
      "[430]\tTest-mae:0.214632\n",
      "[431]\tTest-mae:0.214547\n",
      "[432]\tTest-mae:0.214463\n",
      "[433]\tTest-mae:0.214378\n",
      "[434]\tTest-mae:0.214292\n",
      "[435]\tTest-mae:0.214207\n",
      "[436]\tTest-mae:0.214124\n",
      "[437]\tTest-mae:0.21404\n",
      "[438]\tTest-mae:0.213963\n",
      "[439]\tTest-mae:0.213888\n",
      "[440]\tTest-mae:0.213813\n",
      "[441]\tTest-mae:0.213737\n",
      "[442]\tTest-mae:0.213663\n",
      "[443]\tTest-mae:0.213587\n",
      "[444]\tTest-mae:0.213503\n",
      "[445]\tTest-mae:0.213419\n",
      "[446]\tTest-mae:0.213343\n",
      "[447]\tTest-mae:0.21326\n",
      "[448]\tTest-mae:0.213184\n",
      "[449]\tTest-mae:0.213102\n",
      "[450]\tTest-mae:0.213027\n",
      "[451]\tTest-mae:0.212946\n",
      "[452]\tTest-mae:0.21287\n",
      "[453]\tTest-mae:0.21279\n",
      "[454]\tTest-mae:0.212711\n",
      "[455]\tTest-mae:0.212638\n",
      "[456]\tTest-mae:0.212559\n",
      "[457]\tTest-mae:0.212487\n",
      "[458]\tTest-mae:0.212409\n",
      "[459]\tTest-mae:0.212334\n",
      "[460]\tTest-mae:0.212262\n",
      "[461]\tTest-mae:0.212187\n",
      "[462]\tTest-mae:0.212112\n",
      "[463]\tTest-mae:0.212042\n",
      "[464]\tTest-mae:0.211966\n",
      "[465]\tTest-mae:0.211892\n",
      "[466]\tTest-mae:0.211826\n",
      "[467]\tTest-mae:0.211752\n",
      "[468]\tTest-mae:0.21168\n",
      "[469]\tTest-mae:0.211607\n",
      "[470]\tTest-mae:0.211538\n",
      "[471]\tTest-mae:0.211466\n",
      "[472]\tTest-mae:0.2114\n",
      "[473]\tTest-mae:0.211333\n",
      "[474]\tTest-mae:0.211262\n",
      "[475]\tTest-mae:0.211192\n",
      "[476]\tTest-mae:0.211128\n",
      "[477]\tTest-mae:0.211066\n",
      "[478]\tTest-mae:0.210996\n",
      "[479]\tTest-mae:0.210935\n",
      "[480]\tTest-mae:0.21087\n",
      "[481]\tTest-mae:0.210801\n",
      "[482]\tTest-mae:0.210732\n",
      "[483]\tTest-mae:0.210672\n",
      "[484]\tTest-mae:0.210605\n",
      "[485]\tTest-mae:0.210538\n",
      "[486]\tTest-mae:0.210475\n",
      "[487]\tTest-mae:0.210408\n",
      "[488]\tTest-mae:0.210342\n",
      "[489]\tTest-mae:0.210276\n",
      "[490]\tTest-mae:0.210215\n",
      "[491]\tTest-mae:0.21015\n",
      "[492]\tTest-mae:0.210087\n",
      "[493]\tTest-mae:0.210029\n",
      "[494]\tTest-mae:0.209965\n",
      "[495]\tTest-mae:0.209901\n",
      "[496]\tTest-mae:0.209845\n",
      "[497]\tTest-mae:0.209783\n",
      "[498]\tTest-mae:0.20972\n",
      "[499]\tTest-mae:0.209664\n",
      "[500]\tTest-mae:0.209602\n",
      "[501]\tTest-mae:0.20954\n",
      "[502]\tTest-mae:0.209484\n",
      "[503]\tTest-mae:0.209423\n",
      "[504]\tTest-mae:0.209364\n",
      "[505]\tTest-mae:0.20931\n",
      "[506]\tTest-mae:0.209252\n",
      "[507]\tTest-mae:0.209194\n",
      "[508]\tTest-mae:0.20914\n",
      "[509]\tTest-mae:0.209083\n",
      "[510]\tTest-mae:0.209027\n",
      "[511]\tTest-mae:0.208971\n",
      "[512]\tTest-mae:0.208922\n",
      "[513]\tTest-mae:0.208867\n",
      "[514]\tTest-mae:0.208813\n",
      "[515]\tTest-mae:0.208758\n",
      "[516]\tTest-mae:0.208705\n",
      "[517]\tTest-mae:0.208651\n",
      "[518]\tTest-mae:0.208602\n",
      "[519]\tTest-mae:0.208547\n",
      "[520]\tTest-mae:0.208494\n",
      "[521]\tTest-mae:0.208445\n",
      "[522]\tTest-mae:0.208394\n",
      "[523]\tTest-mae:0.208346\n",
      "[524]\tTest-mae:0.208296\n",
      "[525]\tTest-mae:0.208248\n",
      "[526]\tTest-mae:0.208197\n",
      "[527]\tTest-mae:0.208147\n",
      "[528]\tTest-mae:0.208096\n",
      "[529]\tTest-mae:0.20805\n",
      "[530]\tTest-mae:0.208001\n",
      "[531]\tTest-mae:0.207951\n",
      "[532]\tTest-mae:0.207907\n",
      "[533]\tTest-mae:0.207859\n",
      "[534]\tTest-mae:0.207811\n",
      "[535]\tTest-mae:0.207766\n",
      "[536]\tTest-mae:0.207718\n",
      "[537]\tTest-mae:0.20767\n",
      "[538]\tTest-mae:0.207623\n",
      "[539]\tTest-mae:0.207579\n",
      "[540]\tTest-mae:0.207533\n",
      "[541]\tTest-mae:0.207486\n",
      "[542]\tTest-mae:0.207443\n",
      "[543]\tTest-mae:0.207397\n",
      "[544]\tTest-mae:0.207352\n",
      "[545]\tTest-mae:0.207308\n",
      "[546]\tTest-mae:0.207262\n",
      "[547]\tTest-mae:0.207217\n",
      "[548]\tTest-mae:0.207171\n",
      "[549]\tTest-mae:0.207128\n",
      "[550]\tTest-mae:0.207082\n",
      "[551]\tTest-mae:0.207038\n",
      "[552]\tTest-mae:0.206992\n",
      "[553]\tTest-mae:0.206949\n",
      "[554]\tTest-mae:0.206904\n",
      "[555]\tTest-mae:0.206864\n",
      "[556]\tTest-mae:0.20682\n",
      "[557]\tTest-mae:0.206776\n",
      "[558]\tTest-mae:0.206733\n",
      "[559]\tTest-mae:0.206694\n",
      "[560]\tTest-mae:0.206651\n",
      "[561]\tTest-mae:0.206607\n",
      "[562]\tTest-mae:0.206565\n",
      "[563]\tTest-mae:0.206523\n",
      "[564]\tTest-mae:0.20648\n",
      "[565]\tTest-mae:0.20644\n",
      "[566]\tTest-mae:0.206398\n",
      "[567]\tTest-mae:0.206358\n",
      "[568]\tTest-mae:0.206317\n",
      "[569]\tTest-mae:0.206276\n",
      "[570]\tTest-mae:0.206239\n",
      "[571]\tTest-mae:0.206201\n",
      "[572]\tTest-mae:0.206163\n",
      "[573]\tTest-mae:0.206125\n",
      "[574]\tTest-mae:0.206088\n",
      "[575]\tTest-mae:0.206051\n",
      "[576]\tTest-mae:0.206013\n",
      "[577]\tTest-mae:0.205978\n",
      "[578]\tTest-mae:0.205941\n",
      "[579]\tTest-mae:0.205903\n",
      "[580]\tTest-mae:0.205868\n",
      "[581]\tTest-mae:0.20583\n",
      "[582]\tTest-mae:0.205796\n",
      "[583]\tTest-mae:0.205761\n",
      "[584]\tTest-mae:0.205723\n",
      "[585]\tTest-mae:0.205688\n",
      "[586]\tTest-mae:0.205649\n",
      "[587]\tTest-mae:0.205611\n",
      "[588]\tTest-mae:0.205577\n",
      "[589]\tTest-mae:0.205542\n",
      "[590]\tTest-mae:0.205507\n",
      "[591]\tTest-mae:0.205471\n",
      "[592]\tTest-mae:0.205437\n",
      "[593]\tTest-mae:0.205404\n",
      "[594]\tTest-mae:0.20537\n",
      "[595]\tTest-mae:0.205337\n",
      "[596]\tTest-mae:0.205304\n",
      "[597]\tTest-mae:0.205271\n",
      "[598]\tTest-mae:0.205237\n",
      "[599]\tTest-mae:0.205203\n",
      "[600]\tTest-mae:0.205172\n",
      "[601]\tTest-mae:0.205138\n",
      "[602]\tTest-mae:0.205107\n",
      "[603]\tTest-mae:0.205074\n",
      "[604]\tTest-mae:0.205042\n",
      "[605]\tTest-mae:0.205011\n",
      "[606]\tTest-mae:0.204979\n",
      "[607]\tTest-mae:0.204947\n",
      "[608]\tTest-mae:0.204914\n",
      "[609]\tTest-mae:0.204884\n",
      "[610]\tTest-mae:0.204853\n",
      "[611]\tTest-mae:0.204818\n",
      "[612]\tTest-mae:0.204784\n",
      "[613]\tTest-mae:0.204752\n",
      "[614]\tTest-mae:0.204722\n",
      "[615]\tTest-mae:0.204689\n",
      "[616]\tTest-mae:0.204658\n",
      "[617]\tTest-mae:0.204626\n",
      "[618]\tTest-mae:0.204595\n",
      "[619]\tTest-mae:0.204564\n",
      "[620]\tTest-mae:0.204532\n",
      "[621]\tTest-mae:0.204501\n",
      "[622]\tTest-mae:0.204471\n",
      "[623]\tTest-mae:0.20444\n",
      "[624]\tTest-mae:0.20441\n",
      "[625]\tTest-mae:0.20438\n",
      "[626]\tTest-mae:0.20435\n",
      "[627]\tTest-mae:0.204321\n",
      "[628]\tTest-mae:0.204289\n",
      "[629]\tTest-mae:0.20426\n",
      "[630]\tTest-mae:0.204231\n",
      "[631]\tTest-mae:0.204201\n",
      "[632]\tTest-mae:0.204171\n",
      "[633]\tTest-mae:0.204143\n",
      "[634]\tTest-mae:0.204116\n",
      "[635]\tTest-mae:0.204087\n",
      "[636]\tTest-mae:0.204059\n",
      "[637]\tTest-mae:0.204023\n",
      "[638]\tTest-mae:0.203994\n",
      "[639]\tTest-mae:0.203967\n",
      "[640]\tTest-mae:0.203942\n",
      "[641]\tTest-mae:0.203906\n",
      "[642]\tTest-mae:0.203879\n",
      "[643]\tTest-mae:0.203853\n",
      "[644]\tTest-mae:0.203818\n",
      "[645]\tTest-mae:0.20379\n",
      "[646]\tTest-mae:0.203765\n",
      "[647]\tTest-mae:0.20373\n",
      "[648]\tTest-mae:0.203704\n",
      "[649]\tTest-mae:0.203678\n",
      "[650]\tTest-mae:0.203644\n",
      "[651]\tTest-mae:0.203619\n",
      "[652]\tTest-mae:0.203596\n",
      "[653]\tTest-mae:0.203571\n",
      "[654]\tTest-mae:0.203547\n",
      "[655]\tTest-mae:0.203519\n",
      "[656]\tTest-mae:0.203495\n",
      "[657]\tTest-mae:0.203469\n",
      "[658]\tTest-mae:0.203445\n",
      "[659]\tTest-mae:0.20342\n",
      "[660]\tTest-mae:0.203396\n",
      "[661]\tTest-mae:0.203368\n",
      "[662]\tTest-mae:0.203345\n",
      "[663]\tTest-mae:0.203321\n",
      "[664]\tTest-mae:0.203293\n",
      "[665]\tTest-mae:0.20327\n",
      "[666]\tTest-mae:0.203242\n",
      "[667]\tTest-mae:0.203219\n",
      "[668]\tTest-mae:0.203195\n",
      "[669]\tTest-mae:0.203169\n",
      "[670]\tTest-mae:0.203142\n",
      "[671]\tTest-mae:0.203117\n",
      "[672]\tTest-mae:0.203092\n",
      "[673]\tTest-mae:0.203069\n",
      "[674]\tTest-mae:0.203043\n",
      "[675]\tTest-mae:0.203018\n",
      "[676]\tTest-mae:0.202992\n",
      "[677]\tTest-mae:0.202967\n",
      "[678]\tTest-mae:0.202943\n",
      "[679]\tTest-mae:0.202917\n",
      "[680]\tTest-mae:0.202891\n",
      "[681]\tTest-mae:0.202863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[682]\tTest-mae:0.202835\n",
      "[683]\tTest-mae:0.202807\n",
      "[684]\tTest-mae:0.202781\n",
      "[685]\tTest-mae:0.202753\n",
      "[686]\tTest-mae:0.202725\n",
      "[687]\tTest-mae:0.202698\n",
      "[688]\tTest-mae:0.202671\n",
      "[689]\tTest-mae:0.202645\n",
      "[690]\tTest-mae:0.202619\n",
      "[691]\tTest-mae:0.202595\n",
      "[692]\tTest-mae:0.202569\n",
      "[693]\tTest-mae:0.202545\n",
      "[694]\tTest-mae:0.202519\n",
      "[695]\tTest-mae:0.202496\n",
      "[696]\tTest-mae:0.202473\n",
      "[697]\tTest-mae:0.202447\n",
      "[698]\tTest-mae:0.202424\n",
      "[699]\tTest-mae:0.2024\n",
      "[700]\tTest-mae:0.20238\n",
      "[701]\tTest-mae:0.202355\n",
      "[702]\tTest-mae:0.202336\n",
      "[703]\tTest-mae:0.202316\n",
      "[704]\tTest-mae:0.202292\n",
      "[705]\tTest-mae:0.202274\n",
      "[706]\tTest-mae:0.202255\n",
      "[707]\tTest-mae:0.202233\n",
      "[708]\tTest-mae:0.202211\n",
      "[709]\tTest-mae:0.202192\n",
      "[710]\tTest-mae:0.202169\n",
      "[711]\tTest-mae:0.202151\n",
      "[712]\tTest-mae:0.202133\n",
      "[713]\tTest-mae:0.202112\n",
      "[714]\tTest-mae:0.202094\n",
      "[715]\tTest-mae:0.202071\n",
      "[716]\tTest-mae:0.202051\n",
      "[717]\tTest-mae:0.202033\n",
      "[718]\tTest-mae:0.202016\n",
      "[719]\tTest-mae:0.202\n",
      "[720]\tTest-mae:0.201977\n",
      "[721]\tTest-mae:0.20196\n",
      "[722]\tTest-mae:0.201943\n",
      "[723]\tTest-mae:0.201922\n",
      "[724]\tTest-mae:0.201902\n",
      "[725]\tTest-mae:0.201886\n",
      "[726]\tTest-mae:0.201864\n",
      "[727]\tTest-mae:0.201846\n",
      "[728]\tTest-mae:0.201829\n",
      "[729]\tTest-mae:0.201813\n",
      "[730]\tTest-mae:0.201793\n",
      "[731]\tTest-mae:0.201774\n",
      "[732]\tTest-mae:0.201756\n",
      "[733]\tTest-mae:0.201736\n",
      "[734]\tTest-mae:0.20172\n",
      "[735]\tTest-mae:0.201699\n",
      "[736]\tTest-mae:0.201681\n",
      "[737]\tTest-mae:0.201664\n",
      "[738]\tTest-mae:0.201646\n",
      "[739]\tTest-mae:0.201628\n",
      "[740]\tTest-mae:0.201608\n",
      "[741]\tTest-mae:0.20159\n",
      "[742]\tTest-mae:0.201572\n",
      "[743]\tTest-mae:0.201556\n",
      "[744]\tTest-mae:0.201539\n",
      "[745]\tTest-mae:0.201517\n",
      "[746]\tTest-mae:0.201496\n",
      "[747]\tTest-mae:0.20148\n",
      "[748]\tTest-mae:0.20146\n",
      "[749]\tTest-mae:0.201441\n",
      "[750]\tTest-mae:0.201421\n",
      "[751]\tTest-mae:0.201401\n",
      "[752]\tTest-mae:0.201382\n",
      "[753]\tTest-mae:0.201365\n",
      "[754]\tTest-mae:0.201348\n",
      "[755]\tTest-mae:0.201331\n",
      "[756]\tTest-mae:0.201316\n",
      "[757]\tTest-mae:0.201299\n",
      "[758]\tTest-mae:0.201282\n",
      "[759]\tTest-mae:0.201267\n",
      "[760]\tTest-mae:0.201248\n",
      "[761]\tTest-mae:0.201229\n",
      "[762]\tTest-mae:0.201212\n",
      "[763]\tTest-mae:0.201193\n",
      "[764]\tTest-mae:0.201178\n",
      "[765]\tTest-mae:0.201159\n",
      "[766]\tTest-mae:0.201143\n",
      "[767]\tTest-mae:0.201128\n",
      "[768]\tTest-mae:0.201113\n",
      "[769]\tTest-mae:0.201097\n",
      "[770]\tTest-mae:0.201082\n",
      "[771]\tTest-mae:0.201064\n",
      "[772]\tTest-mae:0.20105\n",
      "[773]\tTest-mae:0.201035\n",
      "[774]\tTest-mae:0.201018\n",
      "[775]\tTest-mae:0.201001\n",
      "[776]\tTest-mae:0.200984\n",
      "[777]\tTest-mae:0.200969\n",
      "[778]\tTest-mae:0.200953\n",
      "[779]\tTest-mae:0.200936\n",
      "[780]\tTest-mae:0.200921\n",
      "[781]\tTest-mae:0.200908\n",
      "[782]\tTest-mae:0.200891\n",
      "[783]\tTest-mae:0.200878\n",
      "[784]\tTest-mae:0.200862\n",
      "[785]\tTest-mae:0.200846\n",
      "[786]\tTest-mae:0.200829\n",
      "[787]\tTest-mae:0.200811\n",
      "[788]\tTest-mae:0.200795\n",
      "[789]\tTest-mae:0.200777\n",
      "[790]\tTest-mae:0.200762\n",
      "[791]\tTest-mae:0.200746\n",
      "[792]\tTest-mae:0.200731\n",
      "[793]\tTest-mae:0.200714\n",
      "[794]\tTest-mae:0.200702\n",
      "[795]\tTest-mae:0.200689\n",
      "[796]\tTest-mae:0.200673\n",
      "[797]\tTest-mae:0.200661\n",
      "[798]\tTest-mae:0.200645\n",
      "[799]\tTest-mae:0.200629\n",
      "[800]\tTest-mae:0.200616\n",
      "[801]\tTest-mae:0.200601\n",
      "[802]\tTest-mae:0.200585\n",
      "[803]\tTest-mae:0.200569\n",
      "[804]\tTest-mae:0.200558\n",
      "[805]\tTest-mae:0.200543\n",
      "[806]\tTest-mae:0.200527\n",
      "[807]\tTest-mae:0.200512\n",
      "[808]\tTest-mae:0.200495\n",
      "[809]\tTest-mae:0.20048\n",
      "[810]\tTest-mae:0.200468\n",
      "[811]\tTest-mae:0.200453\n",
      "[812]\tTest-mae:0.200441\n",
      "[813]\tTest-mae:0.200427\n",
      "[814]\tTest-mae:0.200411\n",
      "[815]\tTest-mae:0.200399\n",
      "[816]\tTest-mae:0.200383\n",
      "[817]\tTest-mae:0.200368\n",
      "[818]\tTest-mae:0.200356\n",
      "[819]\tTest-mae:0.200341\n",
      "[820]\tTest-mae:0.200326\n",
      "[821]\tTest-mae:0.200314\n",
      "[822]\tTest-mae:0.200304\n",
      "[823]\tTest-mae:0.200288\n",
      "[824]\tTest-mae:0.200275\n",
      "[825]\tTest-mae:0.200261\n",
      "[826]\tTest-mae:0.200249\n",
      "[827]\tTest-mae:0.200237\n",
      "[828]\tTest-mae:0.200225\n",
      "[829]\tTest-mae:0.200211\n",
      "[830]\tTest-mae:0.200197\n",
      "[831]\tTest-mae:0.200182\n",
      "[832]\tTest-mae:0.200168\n",
      "[833]\tTest-mae:0.200158\n",
      "[834]\tTest-mae:0.200143\n",
      "[835]\tTest-mae:0.200129\n",
      "[836]\tTest-mae:0.20012\n",
      "[837]\tTest-mae:0.200106\n",
      "[838]\tTest-mae:0.200097\n",
      "[839]\tTest-mae:0.200084\n",
      "[840]\tTest-mae:0.20007\n",
      "[841]\tTest-mae:0.200058\n",
      "[842]\tTest-mae:0.200047\n",
      "[843]\tTest-mae:0.200034\n",
      "[844]\tTest-mae:0.200021\n",
      "[845]\tTest-mae:0.200007\n",
      "[846]\tTest-mae:0.199993\n",
      "[847]\tTest-mae:0.199983\n",
      "[848]\tTest-mae:0.199971\n",
      "[849]\tTest-mae:0.199963\n",
      "[850]\tTest-mae:0.19995\n",
      "[851]\tTest-mae:0.199937\n",
      "[852]\tTest-mae:0.199923\n",
      "[853]\tTest-mae:0.199913\n",
      "[854]\tTest-mae:0.199904\n",
      "[855]\tTest-mae:0.199895\n",
      "[856]\tTest-mae:0.199886\n",
      "[857]\tTest-mae:0.199873\n",
      "[858]\tTest-mae:0.199861\n",
      "[859]\tTest-mae:0.199852\n",
      "[860]\tTest-mae:0.199842\n",
      "[861]\tTest-mae:0.199828\n",
      "[862]\tTest-mae:0.199815\n",
      "[863]\tTest-mae:0.199807\n",
      "[864]\tTest-mae:0.199793\n",
      "[865]\tTest-mae:0.199783\n",
      "[866]\tTest-mae:0.199771\n",
      "[867]\tTest-mae:0.199762\n",
      "[868]\tTest-mae:0.199753\n",
      "[869]\tTest-mae:0.199745\n",
      "[870]\tTest-mae:0.199734\n",
      "[871]\tTest-mae:0.199721\n",
      "[872]\tTest-mae:0.199713\n",
      "[873]\tTest-mae:0.199704\n",
      "[874]\tTest-mae:0.199691\n",
      "[875]\tTest-mae:0.199683\n",
      "[876]\tTest-mae:0.199669\n",
      "[877]\tTest-mae:0.199657\n",
      "[878]\tTest-mae:0.199646\n",
      "[879]\tTest-mae:0.199635\n",
      "[880]\tTest-mae:0.199624\n",
      "[881]\tTest-mae:0.199613\n",
      "[882]\tTest-mae:0.199606\n",
      "[883]\tTest-mae:0.199596\n",
      "[884]\tTest-mae:0.199588\n",
      "[885]\tTest-mae:0.199577\n",
      "[886]\tTest-mae:0.199566\n",
      "[887]\tTest-mae:0.199557\n",
      "[888]\tTest-mae:0.199545\n",
      "[889]\tTest-mae:0.199536\n",
      "[890]\tTest-mae:0.199526\n",
      "[891]\tTest-mae:0.199518\n",
      "[892]\tTest-mae:0.199507\n",
      "[893]\tTest-mae:0.199499\n",
      "[894]\tTest-mae:0.199488\n",
      "[895]\tTest-mae:0.199479\n",
      "[896]\tTest-mae:0.199471\n",
      "[897]\tTest-mae:0.199462\n",
      "[898]\tTest-mae:0.199451\n",
      "[899]\tTest-mae:0.199442\n",
      "[900]\tTest-mae:0.199434\n",
      "[901]\tTest-mae:0.199425\n",
      "[902]\tTest-mae:0.199416\n",
      "[903]\tTest-mae:0.199406\n",
      "[904]\tTest-mae:0.199398\n",
      "[905]\tTest-mae:0.199391\n",
      "[906]\tTest-mae:0.19938\n",
      "[907]\tTest-mae:0.199373\n",
      "[908]\tTest-mae:0.199361\n",
      "[909]\tTest-mae:0.199353\n",
      "[910]\tTest-mae:0.199346\n",
      "[911]\tTest-mae:0.199338\n",
      "[912]\tTest-mae:0.19933\n",
      "[913]\tTest-mae:0.199321\n",
      "[914]\tTest-mae:0.199313\n",
      "[915]\tTest-mae:0.199306\n",
      "[916]\tTest-mae:0.199298\n",
      "[917]\tTest-mae:0.199287\n",
      "[918]\tTest-mae:0.199276\n",
      "[919]\tTest-mae:0.199265\n",
      "[920]\tTest-mae:0.199255\n",
      "[921]\tTest-mae:0.199248\n",
      "[922]\tTest-mae:0.19924\n",
      "[923]\tTest-mae:0.199233\n",
      "[924]\tTest-mae:0.199223\n",
      "[925]\tTest-mae:0.199215\n",
      "[926]\tTest-mae:0.199209\n",
      "[927]\tTest-mae:0.1992\n",
      "[928]\tTest-mae:0.19919\n",
      "[929]\tTest-mae:0.199183\n",
      "[930]\tTest-mae:0.199173\n",
      "[931]\tTest-mae:0.199166\n",
      "[932]\tTest-mae:0.199158\n",
      "[933]\tTest-mae:0.199151\n",
      "[934]\tTest-mae:0.199142\n",
      "[935]\tTest-mae:0.199135\n",
      "[936]\tTest-mae:0.199126\n",
      "[937]\tTest-mae:0.199119\n",
      "[938]\tTest-mae:0.199112\n",
      "[939]\tTest-mae:0.199104\n",
      "[940]\tTest-mae:0.199097\n",
      "[941]\tTest-mae:0.199089\n",
      "[942]\tTest-mae:0.199082\n",
      "[943]\tTest-mae:0.199074\n",
      "[944]\tTest-mae:0.199067\n",
      "[945]\tTest-mae:0.199061\n",
      "[946]\tTest-mae:0.199053\n",
      "[947]\tTest-mae:0.199047\n",
      "[948]\tTest-mae:0.19904\n",
      "[949]\tTest-mae:0.199033\n",
      "[950]\tTest-mae:0.199027\n",
      "[951]\tTest-mae:0.19902\n",
      "[952]\tTest-mae:0.199013\n",
      "[953]\tTest-mae:0.199007\n",
      "[954]\tTest-mae:0.198995\n",
      "[955]\tTest-mae:0.198983\n",
      "[956]\tTest-mae:0.198971\n",
      "[957]\tTest-mae:0.198964\n",
      "[958]\tTest-mae:0.198958\n",
      "[959]\tTest-mae:0.198952\n",
      "[960]\tTest-mae:0.198946\n",
      "[961]\tTest-mae:0.19894\n",
      "[962]\tTest-mae:0.198932\n",
      "[963]\tTest-mae:0.198927\n",
      "[964]\tTest-mae:0.198921\n",
      "[965]\tTest-mae:0.198916\n",
      "[966]\tTest-mae:0.198906\n",
      "[967]\tTest-mae:0.1989\n",
      "[968]\tTest-mae:0.19889\n",
      "[969]\tTest-mae:0.198885\n",
      "[970]\tTest-mae:0.198874\n",
      "[971]\tTest-mae:0.198869\n",
      "[972]\tTest-mae:0.198864\n",
      "[973]\tTest-mae:0.198852\n",
      "[974]\tTest-mae:0.198846\n",
      "[975]\tTest-mae:0.198835\n",
      "[976]\tTest-mae:0.19883\n",
      "[977]\tTest-mae:0.198819\n",
      "[978]\tTest-mae:0.198814\n",
      "[979]\tTest-mae:0.198806\n",
      "[980]\tTest-mae:0.198795\n",
      "[981]\tTest-mae:0.19879\n",
      "[982]\tTest-mae:0.198783\n",
      "[983]\tTest-mae:0.198777\n",
      "[984]\tTest-mae:0.19877\n",
      "[985]\tTest-mae:0.198762\n",
      "[986]\tTest-mae:0.198757\n",
      "[987]\tTest-mae:0.198746\n",
      "[988]\tTest-mae:0.198741\n",
      "[989]\tTest-mae:0.198734\n",
      "[990]\tTest-mae:0.198723\n",
      "[991]\tTest-mae:0.198718\n",
      "[992]\tTest-mae:0.198712\n",
      "[993]\tTest-mae:0.198708\n",
      "[994]\tTest-mae:0.198701\n",
      "[995]\tTest-mae:0.198695\n",
      "[996]\tTest-mae:0.19869\n",
      "[997]\tTest-mae:0.198683\n",
      "[998]\tTest-mae:0.198676\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 0.20 in 999 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:03:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tTest-mae:0.357788\n",
      "[1]\tTest-mae:0.356929\n",
      "[2]\tTest-mae:0.356076\n",
      "[3]\tTest-mae:0.355226\n",
      "[4]\tTest-mae:0.354381\n",
      "[5]\tTest-mae:0.35354\n",
      "[6]\tTest-mae:0.352703\n",
      "[7]\tTest-mae:0.351869\n",
      "[8]\tTest-mae:0.351039\n",
      "[9]\tTest-mae:0.350215\n",
      "[10]\tTest-mae:0.349392\n",
      "[11]\tTest-mae:0.348575\n",
      "[12]\tTest-mae:0.347765\n",
      "[13]\tTest-mae:0.346955\n",
      "[14]\tTest-mae:0.34615\n",
      "[15]\tTest-mae:0.345348\n",
      "[16]\tTest-mae:0.344553\n",
      "[17]\tTest-mae:0.343758\n",
      "[18]\tTest-mae:0.34297\n",
      "[19]\tTest-mae:0.342184\n",
      "[20]\tTest-mae:0.341402\n",
      "[21]\tTest-mae:0.340625\n",
      "[22]\tTest-mae:0.339851\n",
      "[23]\tTest-mae:0.339082\n",
      "[24]\tTest-mae:0.338317\n",
      "[25]\tTest-mae:0.337556\n",
      "[26]\tTest-mae:0.336797\n",
      "[27]\tTest-mae:0.336043\n",
      "[28]\tTest-mae:0.335293\n",
      "[29]\tTest-mae:0.334546\n",
      "[30]\tTest-mae:0.333802\n",
      "[31]\tTest-mae:0.333062\n",
      "[32]\tTest-mae:0.332326\n",
      "[33]\tTest-mae:0.331594\n",
      "[34]\tTest-mae:0.330867\n",
      "[35]\tTest-mae:0.330142\n",
      "[36]\tTest-mae:0.32942\n",
      "[37]\tTest-mae:0.328703\n",
      "[38]\tTest-mae:0.32799\n",
      "[39]\tTest-mae:0.327278\n",
      "[40]\tTest-mae:0.326572\n",
      "[41]\tTest-mae:0.325868\n",
      "[42]\tTest-mae:0.325168\n",
      "[43]\tTest-mae:0.324472\n",
      "[44]\tTest-mae:0.32378\n",
      "[45]\tTest-mae:0.32309\n",
      "[46]\tTest-mae:0.322405\n",
      "[47]\tTest-mae:0.321723\n",
      "[48]\tTest-mae:0.321044\n",
      "[49]\tTest-mae:0.320368\n",
      "[50]\tTest-mae:0.319699\n",
      "[51]\tTest-mae:0.31903\n",
      "[52]\tTest-mae:0.318365\n",
      "[53]\tTest-mae:0.317704\n",
      "[54]\tTest-mae:0.317046\n",
      "[55]\tTest-mae:0.316389\n",
      "[56]\tTest-mae:0.31574\n",
      "[57]\tTest-mae:0.315093\n",
      "[58]\tTest-mae:0.314447\n",
      "[59]\tTest-mae:0.313806\n",
      "[60]\tTest-mae:0.31317\n",
      "[61]\tTest-mae:0.312536\n",
      "[62]\tTest-mae:0.311903\n",
      "[63]\tTest-mae:0.311275\n",
      "[64]\tTest-mae:0.310652\n",
      "[65]\tTest-mae:0.310028\n",
      "[66]\tTest-mae:0.309411\n",
      "[67]\tTest-mae:0.308797\n",
      "[68]\tTest-mae:0.308185\n",
      "[69]\tTest-mae:0.307578\n",
      "[70]\tTest-mae:0.306972\n",
      "[71]\tTest-mae:0.30637\n",
      "[72]\tTest-mae:0.305773\n",
      "[73]\tTest-mae:0.305179\n",
      "[74]\tTest-mae:0.304587\n",
      "[75]\tTest-mae:0.303998\n",
      "[76]\tTest-mae:0.303415\n",
      "[77]\tTest-mae:0.302834\n",
      "[78]\tTest-mae:0.302253\n",
      "[79]\tTest-mae:0.301678\n",
      "[80]\tTest-mae:0.301105\n",
      "[81]\tTest-mae:0.300535\n",
      "[82]\tTest-mae:0.29997\n",
      "[83]\tTest-mae:0.299408\n",
      "[84]\tTest-mae:0.298847\n",
      "[85]\tTest-mae:0.29829\n",
      "[86]\tTest-mae:0.297738\n",
      "[87]\tTest-mae:0.29719\n",
      "[88]\tTest-mae:0.296641\n",
      "[89]\tTest-mae:0.296097\n",
      "[90]\tTest-mae:0.295556\n",
      "[91]\tTest-mae:0.295018\n",
      "[92]\tTest-mae:0.294482\n",
      "[93]\tTest-mae:0.293947\n",
      "[94]\tTest-mae:0.293415\n",
      "[95]\tTest-mae:0.292888\n",
      "[96]\tTest-mae:0.292364\n",
      "[97]\tTest-mae:0.291842\n",
      "[98]\tTest-mae:0.291324\n",
      "[99]\tTest-mae:0.290809\n",
      "[100]\tTest-mae:0.290293\n",
      "[101]\tTest-mae:0.289782\n",
      "[102]\tTest-mae:0.289275\n",
      "[103]\tTest-mae:0.288769\n",
      "[104]\tTest-mae:0.288269\n",
      "[105]\tTest-mae:0.287767\n",
      "[106]\tTest-mae:0.287271\n",
      "[107]\tTest-mae:0.286774\n",
      "[108]\tTest-mae:0.286282\n",
      "[109]\tTest-mae:0.28579\n",
      "[110]\tTest-mae:0.285303\n",
      "[111]\tTest-mae:0.284819\n",
      "[112]\tTest-mae:0.284334\n",
      "[113]\tTest-mae:0.283855\n",
      "[114]\tTest-mae:0.28338\n",
      "[115]\tTest-mae:0.282909\n",
      "[116]\tTest-mae:0.282437\n",
      "[117]\tTest-mae:0.281967\n",
      "[118]\tTest-mae:0.281501\n",
      "[119]\tTest-mae:0.281039\n",
      "[120]\tTest-mae:0.280577\n",
      "[121]\tTest-mae:0.280117\n",
      "[122]\tTest-mae:0.279662\n",
      "[123]\tTest-mae:0.279209\n",
      "[124]\tTest-mae:0.278754\n",
      "[125]\tTest-mae:0.278302\n",
      "[126]\tTest-mae:0.277853\n",
      "[127]\tTest-mae:0.277408\n",
      "[128]\tTest-mae:0.276971\n",
      "[129]\tTest-mae:0.276532\n",
      "[130]\tTest-mae:0.276095\n",
      "[131]\tTest-mae:0.275662\n",
      "[132]\tTest-mae:0.275232\n",
      "[133]\tTest-mae:0.274806\n",
      "[134]\tTest-mae:0.274384\n",
      "[135]\tTest-mae:0.273963\n",
      "[136]\tTest-mae:0.273546\n",
      "[137]\tTest-mae:0.273129\n",
      "[138]\tTest-mae:0.272715\n",
      "[139]\tTest-mae:0.272304\n",
      "[140]\tTest-mae:0.271894\n",
      "[141]\tTest-mae:0.271488\n",
      "[142]\tTest-mae:0.271083\n",
      "[143]\tTest-mae:0.270683\n",
      "[144]\tTest-mae:0.270284\n",
      "[145]\tTest-mae:0.269887\n",
      "[146]\tTest-mae:0.269491\n",
      "[147]\tTest-mae:0.269098\n",
      "[148]\tTest-mae:0.268708\n",
      "[149]\tTest-mae:0.268321\n",
      "[150]\tTest-mae:0.267937\n",
      "[151]\tTest-mae:0.267552\n",
      "[152]\tTest-mae:0.267173\n",
      "[153]\tTest-mae:0.26679\n",
      "[154]\tTest-mae:0.266413\n",
      "[155]\tTest-mae:0.266036\n",
      "[156]\tTest-mae:0.265662\n",
      "[157]\tTest-mae:0.26529\n",
      "[158]\tTest-mae:0.264921\n",
      "[159]\tTest-mae:0.264551\n",
      "[160]\tTest-mae:0.264186\n",
      "[161]\tTest-mae:0.263822\n",
      "[162]\tTest-mae:0.263461\n",
      "[163]\tTest-mae:0.2631\n",
      "[164]\tTest-mae:0.262744\n",
      "[165]\tTest-mae:0.262388\n",
      "[166]\tTest-mae:0.262037\n",
      "[167]\tTest-mae:0.261686\n",
      "[168]\tTest-mae:0.261337\n",
      "[169]\tTest-mae:0.260995\n",
      "[170]\tTest-mae:0.260653\n",
      "[171]\tTest-mae:0.260319\n",
      "[172]\tTest-mae:0.259987\n",
      "[173]\tTest-mae:0.259657\n",
      "[174]\tTest-mae:0.259327\n",
      "[175]\tTest-mae:0.259002\n",
      "[176]\tTest-mae:0.258675\n",
      "[177]\tTest-mae:0.258355\n",
      "[178]\tTest-mae:0.258038\n",
      "[179]\tTest-mae:0.257719\n",
      "[180]\tTest-mae:0.257405\n",
      "[181]\tTest-mae:0.257092\n",
      "[182]\tTest-mae:0.256778\n",
      "[183]\tTest-mae:0.256463\n",
      "[184]\tTest-mae:0.256154\n",
      "[185]\tTest-mae:0.255843\n",
      "[186]\tTest-mae:0.255534\n",
      "[187]\tTest-mae:0.255228\n",
      "[188]\tTest-mae:0.254924\n",
      "[189]\tTest-mae:0.254622\n",
      "[190]\tTest-mae:0.254319\n",
      "[191]\tTest-mae:0.25402\n",
      "[192]\tTest-mae:0.253721\n",
      "[193]\tTest-mae:0.253425\n",
      "[194]\tTest-mae:0.253135\n",
      "[195]\tTest-mae:0.252848\n",
      "[196]\tTest-mae:0.252558\n",
      "[197]\tTest-mae:0.252275\n",
      "[198]\tTest-mae:0.25199\n",
      "[199]\tTest-mae:0.251708\n",
      "[200]\tTest-mae:0.251425\n",
      "[201]\tTest-mae:0.251145\n",
      "[202]\tTest-mae:0.250867\n",
      "[203]\tTest-mae:0.25059\n",
      "[204]\tTest-mae:0.250313\n",
      "[205]\tTest-mae:0.25004\n",
      "[206]\tTest-mae:0.249767\n",
      "[207]\tTest-mae:0.249495\n",
      "[208]\tTest-mae:0.249225\n",
      "[209]\tTest-mae:0.248957\n",
      "[210]\tTest-mae:0.248689\n",
      "[211]\tTest-mae:0.248422\n",
      "[212]\tTest-mae:0.248159\n",
      "[213]\tTest-mae:0.247896\n",
      "[214]\tTest-mae:0.247635\n",
      "[215]\tTest-mae:0.247375\n",
      "[216]\tTest-mae:0.247117\n",
      "[217]\tTest-mae:0.24686\n",
      "[218]\tTest-mae:0.246604\n",
      "[219]\tTest-mae:0.246351\n",
      "[220]\tTest-mae:0.2461\n",
      "[221]\tTest-mae:0.245847\n",
      "[222]\tTest-mae:0.245598\n",
      "[223]\tTest-mae:0.245348\n",
      "[224]\tTest-mae:0.245101\n",
      "[225]\tTest-mae:0.244854\n",
      "[226]\tTest-mae:0.24461\n",
      "[227]\tTest-mae:0.244367\n",
      "[228]\tTest-mae:0.244125\n",
      "[229]\tTest-mae:0.243885\n",
      "[230]\tTest-mae:0.243645\n",
      "[231]\tTest-mae:0.243407\n",
      "[232]\tTest-mae:0.243165\n",
      "[233]\tTest-mae:0.242932\n",
      "[234]\tTest-mae:0.242697\n",
      "[235]\tTest-mae:0.242462\n",
      "[236]\tTest-mae:0.242231\n",
      "[237]\tTest-mae:0.241998\n",
      "[238]\tTest-mae:0.241767\n",
      "[239]\tTest-mae:0.241538\n",
      "[240]\tTest-mae:0.241312\n",
      "[241]\tTest-mae:0.241086\n",
      "[242]\tTest-mae:0.240862\n",
      "[243]\tTest-mae:0.240638\n",
      "[244]\tTest-mae:0.240416\n",
      "[245]\tTest-mae:0.240195\n",
      "[246]\tTest-mae:0.239977\n",
      "[247]\tTest-mae:0.239758\n",
      "[248]\tTest-mae:0.239544\n",
      "[249]\tTest-mae:0.239329\n",
      "[250]\tTest-mae:0.239115\n",
      "[251]\tTest-mae:0.238903\n",
      "[252]\tTest-mae:0.238691\n",
      "[253]\tTest-mae:0.238481\n",
      "[254]\tTest-mae:0.238273\n",
      "[255]\tTest-mae:0.238065\n",
      "[256]\tTest-mae:0.237856\n",
      "[257]\tTest-mae:0.237651\n",
      "[258]\tTest-mae:0.237446\n",
      "[259]\tTest-mae:0.237243\n",
      "[260]\tTest-mae:0.237041\n",
      "[261]\tTest-mae:0.236837\n",
      "[262]\tTest-mae:0.236637\n",
      "[263]\tTest-mae:0.236438\n",
      "[264]\tTest-mae:0.236239\n",
      "[265]\tTest-mae:0.236045\n",
      "[266]\tTest-mae:0.235848\n",
      "[267]\tTest-mae:0.235655\n",
      "[268]\tTest-mae:0.235462\n",
      "[269]\tTest-mae:0.235272\n",
      "[270]\tTest-mae:0.235082\n",
      "[271]\tTest-mae:0.234892\n",
      "[272]\tTest-mae:0.234702\n",
      "[273]\tTest-mae:0.234515\n",
      "[274]\tTest-mae:0.234329\n",
      "[275]\tTest-mae:0.234145\n",
      "[276]\tTest-mae:0.233959\n",
      "[277]\tTest-mae:0.233777\n",
      "[278]\tTest-mae:0.233591\n",
      "[279]\tTest-mae:0.23341\n",
      "[280]\tTest-mae:0.233232\n",
      "[281]\tTest-mae:0.233053\n",
      "[282]\tTest-mae:0.232878\n",
      "[283]\tTest-mae:0.232701\n",
      "[284]\tTest-mae:0.232528\n",
      "[285]\tTest-mae:0.232351\n",
      "[286]\tTest-mae:0.23218\n",
      "[287]\tTest-mae:0.232007\n",
      "[288]\tTest-mae:0.231832\n",
      "[289]\tTest-mae:0.231662\n",
      "[290]\tTest-mae:0.231494\n",
      "[291]\tTest-mae:0.231323\n",
      "[292]\tTest-mae:0.231156\n",
      "[293]\tTest-mae:0.230986\n",
      "[294]\tTest-mae:0.230819\n",
      "[295]\tTest-mae:0.230653\n",
      "[296]\tTest-mae:0.230485\n",
      "[297]\tTest-mae:0.230321\n",
      "[298]\tTest-mae:0.230159\n",
      "[299]\tTest-mae:0.229998\n",
      "[300]\tTest-mae:0.229836\n",
      "[301]\tTest-mae:0.229676\n",
      "[302]\tTest-mae:0.229518\n",
      "[303]\tTest-mae:0.229358\n",
      "[304]\tTest-mae:0.229204\n",
      "[305]\tTest-mae:0.229045\n",
      "[306]\tTest-mae:0.22889\n",
      "[307]\tTest-mae:0.228736\n",
      "[308]\tTest-mae:0.228575\n",
      "[309]\tTest-mae:0.228424\n",
      "[310]\tTest-mae:0.228272\n",
      "[311]\tTest-mae:0.228122\n",
      "[312]\tTest-mae:0.22797\n",
      "[313]\tTest-mae:0.22782\n",
      "[314]\tTest-mae:0.227673\n",
      "[315]\tTest-mae:0.227524\n",
      "[316]\tTest-mae:0.227371\n",
      "[317]\tTest-mae:0.227225\n",
      "[318]\tTest-mae:0.227077\n",
      "[319]\tTest-mae:0.226934\n",
      "[320]\tTest-mae:0.22679\n",
      "[321]\tTest-mae:0.226647\n",
      "[322]\tTest-mae:0.226504\n",
      "[323]\tTest-mae:0.226362\n",
      "[324]\tTest-mae:0.22622\n",
      "[325]\tTest-mae:0.226078\n",
      "[326]\tTest-mae:0.22594\n",
      "[327]\tTest-mae:0.225802\n",
      "[328]\tTest-mae:0.225663\n",
      "[329]\tTest-mae:0.225524\n",
      "[330]\tTest-mae:0.225382\n",
      "[331]\tTest-mae:0.225245\n",
      "[332]\tTest-mae:0.225112\n",
      "[333]\tTest-mae:0.224974\n",
      "[334]\tTest-mae:0.224835\n",
      "[335]\tTest-mae:0.224703\n",
      "[336]\tTest-mae:0.22457\n",
      "[337]\tTest-mae:0.224439\n",
      "[338]\tTest-mae:0.224306\n",
      "[339]\tTest-mae:0.224169\n",
      "[340]\tTest-mae:0.22404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[341]\tTest-mae:0.223903\n",
      "[342]\tTest-mae:0.223774\n",
      "[343]\tTest-mae:0.223641\n",
      "[344]\tTest-mae:0.223512\n",
      "[345]\tTest-mae:0.223381\n",
      "[346]\tTest-mae:0.22325\n",
      "[347]\tTest-mae:0.223123\n",
      "[348]\tTest-mae:0.222994\n",
      "[349]\tTest-mae:0.222868\n",
      "[350]\tTest-mae:0.222743\n",
      "[351]\tTest-mae:0.222617\n",
      "[352]\tTest-mae:0.222493\n",
      "[353]\tTest-mae:0.22237\n",
      "[354]\tTest-mae:0.222245\n",
      "[355]\tTest-mae:0.222124\n",
      "[356]\tTest-mae:0.222005\n",
      "[357]\tTest-mae:0.221882\n",
      "[358]\tTest-mae:0.221762\n",
      "[359]\tTest-mae:0.221645\n",
      "[360]\tTest-mae:0.221525\n",
      "[361]\tTest-mae:0.221405\n",
      "[362]\tTest-mae:0.221289\n",
      "[363]\tTest-mae:0.221172\n",
      "[364]\tTest-mae:0.221059\n",
      "[365]\tTest-mae:0.220942\n",
      "[366]\tTest-mae:0.220831\n",
      "[367]\tTest-mae:0.220715\n",
      "[368]\tTest-mae:0.220603\n",
      "[369]\tTest-mae:0.220488\n",
      "[370]\tTest-mae:0.220378\n",
      "[371]\tTest-mae:0.220269\n",
      "[372]\tTest-mae:0.220157\n",
      "[373]\tTest-mae:0.220048\n",
      "[374]\tTest-mae:0.219941\n",
      "[375]\tTest-mae:0.219831\n",
      "[376]\tTest-mae:0.219725\n",
      "[377]\tTest-mae:0.21962\n",
      "[378]\tTest-mae:0.219512\n",
      "[379]\tTest-mae:0.219404\n",
      "[380]\tTest-mae:0.219302\n",
      "[381]\tTest-mae:0.2192\n",
      "[382]\tTest-mae:0.219095\n",
      "[383]\tTest-mae:0.218988\n",
      "[384]\tTest-mae:0.218884\n",
      "[385]\tTest-mae:0.218782\n",
      "[386]\tTest-mae:0.218679\n",
      "[387]\tTest-mae:0.218576\n",
      "[388]\tTest-mae:0.218476\n",
      "[389]\tTest-mae:0.218374\n",
      "[390]\tTest-mae:0.218274\n",
      "[391]\tTest-mae:0.218174\n",
      "[392]\tTest-mae:0.218075\n",
      "[393]\tTest-mae:0.217979\n",
      "[394]\tTest-mae:0.217883\n",
      "[395]\tTest-mae:0.217789\n",
      "[396]\tTest-mae:0.217696\n",
      "[397]\tTest-mae:0.2176\n",
      "[398]\tTest-mae:0.217503\n",
      "[399]\tTest-mae:0.217409\n",
      "[400]\tTest-mae:0.217317\n",
      "[401]\tTest-mae:0.217228\n",
      "[402]\tTest-mae:0.217136\n",
      "[403]\tTest-mae:0.217043\n",
      "[404]\tTest-mae:0.21695\n",
      "[405]\tTest-mae:0.216858\n",
      "[406]\tTest-mae:0.216759\n",
      "[407]\tTest-mae:0.216665\n",
      "[408]\tTest-mae:0.216574\n",
      "[409]\tTest-mae:0.216477\n",
      "[410]\tTest-mae:0.216384\n",
      "[411]\tTest-mae:0.216288\n",
      "[412]\tTest-mae:0.216199\n",
      "[413]\tTest-mae:0.216104\n",
      "[414]\tTest-mae:0.216016\n",
      "[415]\tTest-mae:0.215925\n",
      "[416]\tTest-mae:0.215831\n",
      "[417]\tTest-mae:0.215746\n",
      "[418]\tTest-mae:0.215653\n",
      "[419]\tTest-mae:0.215569\n",
      "[420]\tTest-mae:0.215485\n",
      "[421]\tTest-mae:0.215395\n",
      "[422]\tTest-mae:0.215312\n",
      "[423]\tTest-mae:0.215221\n",
      "[424]\tTest-mae:0.215141\n",
      "[425]\tTest-mae:0.21505\n",
      "[426]\tTest-mae:0.214971\n",
      "[427]\tTest-mae:0.214891\n",
      "[428]\tTest-mae:0.214805\n",
      "[429]\tTest-mae:0.214718\n",
      "[430]\tTest-mae:0.214632\n",
      "[431]\tTest-mae:0.214547\n",
      "[432]\tTest-mae:0.214463\n",
      "[433]\tTest-mae:0.214378\n",
      "[434]\tTest-mae:0.214292\n",
      "[435]\tTest-mae:0.214207\n",
      "[436]\tTest-mae:0.214124\n",
      "[437]\tTest-mae:0.21404\n",
      "[438]\tTest-mae:0.213963\n",
      "[439]\tTest-mae:0.213888\n",
      "[440]\tTest-mae:0.213813\n",
      "[441]\tTest-mae:0.213737\n",
      "[442]\tTest-mae:0.213663\n",
      "[443]\tTest-mae:0.213587\n",
      "[444]\tTest-mae:0.213503\n",
      "[445]\tTest-mae:0.213419\n",
      "[446]\tTest-mae:0.213343\n",
      "[447]\tTest-mae:0.21326\n",
      "[448]\tTest-mae:0.213184\n",
      "[449]\tTest-mae:0.213102\n",
      "[450]\tTest-mae:0.213027\n",
      "[451]\tTest-mae:0.212946\n",
      "[452]\tTest-mae:0.21287\n",
      "[453]\tTest-mae:0.21279\n",
      "[454]\tTest-mae:0.212711\n",
      "[455]\tTest-mae:0.212638\n",
      "[456]\tTest-mae:0.212559\n",
      "[457]\tTest-mae:0.212487\n",
      "[458]\tTest-mae:0.212409\n",
      "[459]\tTest-mae:0.212334\n",
      "[460]\tTest-mae:0.212262\n",
      "[461]\tTest-mae:0.212187\n",
      "[462]\tTest-mae:0.212112\n",
      "[463]\tTest-mae:0.212042\n",
      "[464]\tTest-mae:0.211966\n",
      "[465]\tTest-mae:0.211892\n",
      "[466]\tTest-mae:0.211826\n",
      "[467]\tTest-mae:0.211752\n",
      "[468]\tTest-mae:0.21168\n",
      "[469]\tTest-mae:0.211607\n",
      "[470]\tTest-mae:0.211538\n",
      "[471]\tTest-mae:0.211466\n",
      "[472]\tTest-mae:0.2114\n",
      "[473]\tTest-mae:0.211333\n",
      "[474]\tTest-mae:0.211262\n",
      "[475]\tTest-mae:0.211192\n",
      "[476]\tTest-mae:0.211128\n",
      "[477]\tTest-mae:0.211066\n",
      "[478]\tTest-mae:0.210996\n",
      "[479]\tTest-mae:0.210935\n",
      "[480]\tTest-mae:0.21087\n",
      "[481]\tTest-mae:0.210801\n",
      "[482]\tTest-mae:0.210732\n",
      "[483]\tTest-mae:0.210672\n",
      "[484]\tTest-mae:0.210605\n",
      "[485]\tTest-mae:0.210538\n",
      "[486]\tTest-mae:0.210475\n",
      "[487]\tTest-mae:0.210408\n",
      "[488]\tTest-mae:0.210342\n",
      "[489]\tTest-mae:0.210276\n",
      "[490]\tTest-mae:0.210215\n",
      "[491]\tTest-mae:0.21015\n",
      "[492]\tTest-mae:0.210087\n",
      "[493]\tTest-mae:0.210029\n",
      "[494]\tTest-mae:0.209965\n",
      "[495]\tTest-mae:0.209901\n",
      "[496]\tTest-mae:0.209845\n",
      "[497]\tTest-mae:0.209783\n",
      "[498]\tTest-mae:0.20972\n",
      "[499]\tTest-mae:0.209664\n",
      "[500]\tTest-mae:0.209602\n",
      "[501]\tTest-mae:0.20954\n",
      "[502]\tTest-mae:0.209484\n",
      "[503]\tTest-mae:0.209423\n",
      "[504]\tTest-mae:0.209364\n",
      "[505]\tTest-mae:0.20931\n",
      "[506]\tTest-mae:0.209252\n",
      "[507]\tTest-mae:0.209194\n",
      "[508]\tTest-mae:0.20914\n",
      "[509]\tTest-mae:0.209083\n",
      "[510]\tTest-mae:0.209027\n",
      "[511]\tTest-mae:0.208971\n",
      "[512]\tTest-mae:0.208922\n",
      "[513]\tTest-mae:0.208867\n",
      "[514]\tTest-mae:0.208813\n",
      "[515]\tTest-mae:0.208758\n",
      "[516]\tTest-mae:0.208705\n",
      "[517]\tTest-mae:0.208651\n",
      "[518]\tTest-mae:0.208602\n",
      "[519]\tTest-mae:0.208547\n",
      "[520]\tTest-mae:0.208494\n",
      "[521]\tTest-mae:0.208445\n",
      "[522]\tTest-mae:0.208394\n",
      "[523]\tTest-mae:0.208346\n",
      "[524]\tTest-mae:0.208296\n",
      "[525]\tTest-mae:0.208248\n",
      "[526]\tTest-mae:0.208197\n",
      "[527]\tTest-mae:0.208147\n",
      "[528]\tTest-mae:0.208096\n",
      "[529]\tTest-mae:0.20805\n",
      "[530]\tTest-mae:0.208001\n",
      "[531]\tTest-mae:0.207951\n",
      "[532]\tTest-mae:0.207907\n",
      "[533]\tTest-mae:0.207859\n",
      "[534]\tTest-mae:0.207811\n",
      "[535]\tTest-mae:0.207766\n",
      "[536]\tTest-mae:0.207718\n",
      "[537]\tTest-mae:0.20767\n",
      "[538]\tTest-mae:0.207623\n",
      "[539]\tTest-mae:0.207579\n",
      "[540]\tTest-mae:0.207533\n",
      "[541]\tTest-mae:0.207486\n",
      "[542]\tTest-mae:0.207443\n",
      "[543]\tTest-mae:0.207397\n",
      "[544]\tTest-mae:0.207352\n",
      "[545]\tTest-mae:0.207308\n",
      "[546]\tTest-mae:0.207262\n",
      "[547]\tTest-mae:0.207217\n",
      "[548]\tTest-mae:0.207171\n",
      "[549]\tTest-mae:0.207128\n",
      "[550]\tTest-mae:0.207082\n",
      "[551]\tTest-mae:0.207038\n",
      "[552]\tTest-mae:0.206992\n",
      "[553]\tTest-mae:0.206949\n",
      "[554]\tTest-mae:0.206904\n",
      "[555]\tTest-mae:0.206864\n",
      "[556]\tTest-mae:0.20682\n",
      "[557]\tTest-mae:0.206776\n",
      "[558]\tTest-mae:0.206733\n",
      "[559]\tTest-mae:0.206694\n",
      "[560]\tTest-mae:0.206651\n",
      "[561]\tTest-mae:0.206607\n",
      "[562]\tTest-mae:0.206565\n",
      "[563]\tTest-mae:0.206523\n",
      "[564]\tTest-mae:0.20648\n",
      "[565]\tTest-mae:0.20644\n",
      "[566]\tTest-mae:0.206398\n",
      "[567]\tTest-mae:0.206358\n",
      "[568]\tTest-mae:0.206317\n",
      "[569]\tTest-mae:0.206276\n",
      "[570]\tTest-mae:0.206239\n",
      "[571]\tTest-mae:0.206201\n",
      "[572]\tTest-mae:0.206163\n",
      "[573]\tTest-mae:0.206125\n",
      "[574]\tTest-mae:0.206088\n",
      "[575]\tTest-mae:0.206051\n",
      "[576]\tTest-mae:0.206013\n",
      "[577]\tTest-mae:0.205978\n",
      "[578]\tTest-mae:0.205941\n",
      "[579]\tTest-mae:0.205903\n",
      "[580]\tTest-mae:0.205868\n",
      "[581]\tTest-mae:0.20583\n",
      "[582]\tTest-mae:0.205796\n",
      "[583]\tTest-mae:0.205761\n",
      "[584]\tTest-mae:0.205723\n",
      "[585]\tTest-mae:0.205688\n",
      "[586]\tTest-mae:0.205649\n",
      "[587]\tTest-mae:0.205611\n",
      "[588]\tTest-mae:0.205577\n",
      "[589]\tTest-mae:0.205542\n",
      "[590]\tTest-mae:0.205507\n",
      "[591]\tTest-mae:0.205471\n",
      "[592]\tTest-mae:0.205437\n",
      "[593]\tTest-mae:0.205404\n",
      "[594]\tTest-mae:0.20537\n",
      "[595]\tTest-mae:0.205337\n",
      "[596]\tTest-mae:0.205304\n",
      "[597]\tTest-mae:0.205271\n",
      "[598]\tTest-mae:0.205237\n",
      "[599]\tTest-mae:0.205203\n",
      "[600]\tTest-mae:0.205172\n",
      "[601]\tTest-mae:0.205138\n",
      "[602]\tTest-mae:0.205107\n",
      "[603]\tTest-mae:0.205074\n",
      "[604]\tTest-mae:0.205042\n",
      "[605]\tTest-mae:0.205011\n",
      "[606]\tTest-mae:0.204979\n",
      "[607]\tTest-mae:0.204947\n",
      "[608]\tTest-mae:0.204914\n",
      "[609]\tTest-mae:0.204884\n",
      "[610]\tTest-mae:0.204853\n",
      "[611]\tTest-mae:0.204818\n",
      "[612]\tTest-mae:0.204784\n",
      "[613]\tTest-mae:0.204752\n",
      "[614]\tTest-mae:0.204722\n",
      "[615]\tTest-mae:0.204689\n",
      "[616]\tTest-mae:0.204658\n",
      "[617]\tTest-mae:0.204626\n",
      "[618]\tTest-mae:0.204595\n",
      "[619]\tTest-mae:0.204564\n",
      "[620]\tTest-mae:0.204532\n",
      "[621]\tTest-mae:0.204501\n",
      "[622]\tTest-mae:0.204471\n",
      "[623]\tTest-mae:0.20444\n",
      "[624]\tTest-mae:0.20441\n",
      "[625]\tTest-mae:0.20438\n",
      "[626]\tTest-mae:0.20435\n",
      "[627]\tTest-mae:0.204321\n",
      "[628]\tTest-mae:0.204289\n",
      "[629]\tTest-mae:0.20426\n",
      "[630]\tTest-mae:0.204231\n",
      "[631]\tTest-mae:0.204201\n",
      "[632]\tTest-mae:0.204171\n",
      "[633]\tTest-mae:0.204143\n",
      "[634]\tTest-mae:0.204116\n",
      "[635]\tTest-mae:0.204087\n",
      "[636]\tTest-mae:0.204059\n",
      "[637]\tTest-mae:0.204023\n",
      "[638]\tTest-mae:0.203994\n",
      "[639]\tTest-mae:0.203967\n",
      "[640]\tTest-mae:0.203942\n",
      "[641]\tTest-mae:0.203906\n",
      "[642]\tTest-mae:0.203879\n",
      "[643]\tTest-mae:0.203853\n",
      "[644]\tTest-mae:0.203818\n",
      "[645]\tTest-mae:0.20379\n",
      "[646]\tTest-mae:0.203765\n",
      "[647]\tTest-mae:0.20373\n",
      "[648]\tTest-mae:0.203704\n",
      "[649]\tTest-mae:0.203678\n",
      "[650]\tTest-mae:0.203644\n",
      "[651]\tTest-mae:0.203619\n",
      "[652]\tTest-mae:0.203596\n",
      "[653]\tTest-mae:0.203571\n",
      "[654]\tTest-mae:0.203547\n",
      "[655]\tTest-mae:0.203519\n",
      "[656]\tTest-mae:0.203495\n",
      "[657]\tTest-mae:0.203469\n",
      "[658]\tTest-mae:0.203445\n",
      "[659]\tTest-mae:0.20342\n",
      "[660]\tTest-mae:0.203396\n",
      "[661]\tTest-mae:0.203368\n",
      "[662]\tTest-mae:0.203345\n",
      "[663]\tTest-mae:0.203321\n",
      "[664]\tTest-mae:0.203293\n",
      "[665]\tTest-mae:0.20327\n",
      "[666]\tTest-mae:0.203242\n",
      "[667]\tTest-mae:0.203219\n",
      "[668]\tTest-mae:0.203195\n",
      "[669]\tTest-mae:0.203169\n",
      "[670]\tTest-mae:0.203142\n",
      "[671]\tTest-mae:0.203117\n",
      "[672]\tTest-mae:0.203092\n",
      "[673]\tTest-mae:0.203069\n",
      "[674]\tTest-mae:0.203043\n",
      "[675]\tTest-mae:0.203018\n",
      "[676]\tTest-mae:0.202992\n",
      "[677]\tTest-mae:0.202967\n",
      "[678]\tTest-mae:0.202943\n",
      "[679]\tTest-mae:0.202917\n",
      "[680]\tTest-mae:0.202891\n",
      "[681]\tTest-mae:0.202863\n",
      "[682]\tTest-mae:0.202835\n",
      "[683]\tTest-mae:0.202807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[684]\tTest-mae:0.202781\n",
      "[685]\tTest-mae:0.202753\n",
      "[686]\tTest-mae:0.202725\n",
      "[687]\tTest-mae:0.202698\n",
      "[688]\tTest-mae:0.202671\n",
      "[689]\tTest-mae:0.202645\n",
      "[690]\tTest-mae:0.202619\n",
      "[691]\tTest-mae:0.202595\n",
      "[692]\tTest-mae:0.202569\n",
      "[693]\tTest-mae:0.202545\n",
      "[694]\tTest-mae:0.202519\n",
      "[695]\tTest-mae:0.202496\n",
      "[696]\tTest-mae:0.202473\n",
      "[697]\tTest-mae:0.202447\n",
      "[698]\tTest-mae:0.202424\n",
      "[699]\tTest-mae:0.2024\n",
      "[700]\tTest-mae:0.20238\n",
      "[701]\tTest-mae:0.202355\n",
      "[702]\tTest-mae:0.202336\n",
      "[703]\tTest-mae:0.202316\n",
      "[704]\tTest-mae:0.202292\n",
      "[705]\tTest-mae:0.202274\n",
      "[706]\tTest-mae:0.202255\n",
      "[707]\tTest-mae:0.202233\n",
      "[708]\tTest-mae:0.202211\n",
      "[709]\tTest-mae:0.202192\n",
      "[710]\tTest-mae:0.202169\n",
      "[711]\tTest-mae:0.202151\n",
      "[712]\tTest-mae:0.202133\n",
      "[713]\tTest-mae:0.202112\n",
      "[714]\tTest-mae:0.202094\n",
      "[715]\tTest-mae:0.202071\n",
      "[716]\tTest-mae:0.202051\n",
      "[717]\tTest-mae:0.202033\n",
      "[718]\tTest-mae:0.202016\n",
      "[719]\tTest-mae:0.202\n",
      "[720]\tTest-mae:0.201977\n",
      "[721]\tTest-mae:0.20196\n",
      "[722]\tTest-mae:0.201943\n",
      "[723]\tTest-mae:0.201922\n",
      "[724]\tTest-mae:0.201902\n",
      "[725]\tTest-mae:0.201886\n",
      "[726]\tTest-mae:0.201864\n",
      "[727]\tTest-mae:0.201846\n",
      "[728]\tTest-mae:0.201829\n",
      "[729]\tTest-mae:0.201813\n",
      "[730]\tTest-mae:0.201793\n",
      "[731]\tTest-mae:0.201774\n",
      "[732]\tTest-mae:0.201756\n",
      "[733]\tTest-mae:0.201736\n",
      "[734]\tTest-mae:0.20172\n",
      "[735]\tTest-mae:0.201699\n",
      "[736]\tTest-mae:0.201681\n",
      "[737]\tTest-mae:0.201664\n",
      "[738]\tTest-mae:0.201646\n",
      "[739]\tTest-mae:0.201628\n",
      "[740]\tTest-mae:0.201608\n",
      "[741]\tTest-mae:0.20159\n",
      "[742]\tTest-mae:0.201572\n",
      "[743]\tTest-mae:0.201556\n",
      "[744]\tTest-mae:0.201539\n",
      "[745]\tTest-mae:0.201517\n",
      "[746]\tTest-mae:0.201496\n",
      "[747]\tTest-mae:0.20148\n",
      "[748]\tTest-mae:0.20146\n",
      "[749]\tTest-mae:0.201441\n",
      "[750]\tTest-mae:0.201421\n",
      "[751]\tTest-mae:0.201401\n",
      "[752]\tTest-mae:0.201382\n",
      "[753]\tTest-mae:0.201365\n",
      "[754]\tTest-mae:0.201348\n",
      "[755]\tTest-mae:0.201331\n",
      "[756]\tTest-mae:0.201316\n",
      "[757]\tTest-mae:0.201299\n",
      "[758]\tTest-mae:0.201282\n",
      "[759]\tTest-mae:0.201267\n",
      "[760]\tTest-mae:0.201248\n",
      "[761]\tTest-mae:0.201229\n",
      "[762]\tTest-mae:0.201212\n",
      "[763]\tTest-mae:0.201193\n",
      "[764]\tTest-mae:0.201178\n",
      "[765]\tTest-mae:0.201159\n",
      "[766]\tTest-mae:0.201143\n",
      "[767]\tTest-mae:0.201128\n",
      "[768]\tTest-mae:0.201113\n",
      "[769]\tTest-mae:0.201097\n",
      "[770]\tTest-mae:0.201082\n",
      "[771]\tTest-mae:0.201064\n",
      "[772]\tTest-mae:0.20105\n",
      "[773]\tTest-mae:0.201035\n",
      "[774]\tTest-mae:0.201018\n",
      "[775]\tTest-mae:0.201001\n",
      "[776]\tTest-mae:0.200984\n",
      "[777]\tTest-mae:0.200969\n",
      "[778]\tTest-mae:0.200953\n",
      "[779]\tTest-mae:0.200936\n",
      "[780]\tTest-mae:0.200921\n",
      "[781]\tTest-mae:0.200908\n",
      "[782]\tTest-mae:0.200891\n",
      "[783]\tTest-mae:0.200878\n",
      "[784]\tTest-mae:0.200862\n",
      "[785]\tTest-mae:0.200846\n",
      "[786]\tTest-mae:0.200829\n",
      "[787]\tTest-mae:0.200811\n",
      "[788]\tTest-mae:0.200795\n",
      "[789]\tTest-mae:0.200777\n",
      "[790]\tTest-mae:0.200762\n",
      "[791]\tTest-mae:0.200746\n",
      "[792]\tTest-mae:0.200731\n",
      "[793]\tTest-mae:0.200714\n",
      "[794]\tTest-mae:0.200702\n",
      "[795]\tTest-mae:0.200689\n",
      "[796]\tTest-mae:0.200673\n",
      "[797]\tTest-mae:0.200661\n",
      "[798]\tTest-mae:0.200645\n",
      "[799]\tTest-mae:0.200629\n",
      "[800]\tTest-mae:0.200616\n",
      "[801]\tTest-mae:0.200601\n",
      "[802]\tTest-mae:0.200585\n",
      "[803]\tTest-mae:0.200569\n",
      "[804]\tTest-mae:0.200558\n",
      "[805]\tTest-mae:0.200543\n",
      "[806]\tTest-mae:0.200527\n",
      "[807]\tTest-mae:0.200512\n",
      "[808]\tTest-mae:0.200495\n",
      "[809]\tTest-mae:0.20048\n",
      "[810]\tTest-mae:0.200468\n",
      "[811]\tTest-mae:0.200453\n",
      "[812]\tTest-mae:0.200441\n",
      "[813]\tTest-mae:0.200427\n",
      "[814]\tTest-mae:0.200411\n",
      "[815]\tTest-mae:0.200399\n",
      "[816]\tTest-mae:0.200383\n",
      "[817]\tTest-mae:0.200368\n",
      "[818]\tTest-mae:0.200356\n",
      "[819]\tTest-mae:0.200341\n",
      "[820]\tTest-mae:0.200326\n",
      "[821]\tTest-mae:0.200314\n",
      "[822]\tTest-mae:0.200304\n",
      "[823]\tTest-mae:0.200288\n",
      "[824]\tTest-mae:0.200275\n",
      "[825]\tTest-mae:0.200261\n",
      "[826]\tTest-mae:0.200249\n",
      "[827]\tTest-mae:0.200237\n",
      "[828]\tTest-mae:0.200225\n",
      "[829]\tTest-mae:0.200211\n",
      "[830]\tTest-mae:0.200197\n",
      "[831]\tTest-mae:0.200182\n",
      "[832]\tTest-mae:0.200168\n",
      "[833]\tTest-mae:0.200158\n",
      "[834]\tTest-mae:0.200143\n",
      "[835]\tTest-mae:0.200129\n",
      "[836]\tTest-mae:0.20012\n",
      "[837]\tTest-mae:0.200106\n",
      "[838]\tTest-mae:0.200097\n",
      "[839]\tTest-mae:0.200084\n",
      "[840]\tTest-mae:0.20007\n",
      "[841]\tTest-mae:0.200058\n",
      "[842]\tTest-mae:0.200047\n",
      "[843]\tTest-mae:0.200034\n",
      "[844]\tTest-mae:0.200021\n",
      "[845]\tTest-mae:0.200007\n",
      "[846]\tTest-mae:0.199993\n",
      "[847]\tTest-mae:0.199983\n",
      "[848]\tTest-mae:0.199971\n",
      "[849]\tTest-mae:0.199963\n",
      "[850]\tTest-mae:0.19995\n",
      "[851]\tTest-mae:0.199937\n",
      "[852]\tTest-mae:0.199923\n",
      "[853]\tTest-mae:0.199913\n",
      "[854]\tTest-mae:0.199904\n",
      "[855]\tTest-mae:0.199895\n",
      "[856]\tTest-mae:0.199886\n",
      "[857]\tTest-mae:0.199873\n",
      "[858]\tTest-mae:0.199861\n",
      "[859]\tTest-mae:0.199852\n",
      "[860]\tTest-mae:0.199842\n",
      "[861]\tTest-mae:0.199828\n",
      "[862]\tTest-mae:0.199815\n",
      "[863]\tTest-mae:0.199807\n",
      "[864]\tTest-mae:0.199793\n",
      "[865]\tTest-mae:0.199783\n",
      "[866]\tTest-mae:0.199771\n",
      "[867]\tTest-mae:0.199762\n",
      "[868]\tTest-mae:0.199753\n",
      "[869]\tTest-mae:0.199745\n",
      "[870]\tTest-mae:0.199734\n",
      "[871]\tTest-mae:0.199721\n",
      "[872]\tTest-mae:0.199713\n",
      "[873]\tTest-mae:0.199704\n",
      "[874]\tTest-mae:0.199691\n",
      "[875]\tTest-mae:0.199683\n",
      "[876]\tTest-mae:0.199669\n",
      "[877]\tTest-mae:0.199657\n",
      "[878]\tTest-mae:0.199646\n",
      "[879]\tTest-mae:0.199635\n",
      "[880]\tTest-mae:0.199624\n",
      "[881]\tTest-mae:0.199613\n",
      "[882]\tTest-mae:0.199606\n",
      "[883]\tTest-mae:0.199596\n",
      "[884]\tTest-mae:0.199588\n",
      "[885]\tTest-mae:0.199577\n",
      "[886]\tTest-mae:0.199566\n",
      "[887]\tTest-mae:0.199557\n",
      "[888]\tTest-mae:0.199545\n",
      "[889]\tTest-mae:0.199536\n",
      "[890]\tTest-mae:0.199526\n",
      "[891]\tTest-mae:0.199518\n",
      "[892]\tTest-mae:0.199507\n",
      "[893]\tTest-mae:0.199499\n",
      "[894]\tTest-mae:0.199488\n",
      "[895]\tTest-mae:0.199479\n",
      "[896]\tTest-mae:0.199471\n",
      "[897]\tTest-mae:0.199462\n",
      "[898]\tTest-mae:0.199451\n",
      "[899]\tTest-mae:0.199442\n",
      "[900]\tTest-mae:0.199434\n",
      "[901]\tTest-mae:0.199425\n",
      "[902]\tTest-mae:0.199416\n",
      "[903]\tTest-mae:0.199406\n",
      "[904]\tTest-mae:0.199398\n",
      "[905]\tTest-mae:0.199391\n",
      "[906]\tTest-mae:0.19938\n",
      "[907]\tTest-mae:0.199373\n",
      "[908]\tTest-mae:0.199361\n",
      "[909]\tTest-mae:0.199353\n",
      "[910]\tTest-mae:0.199346\n",
      "[911]\tTest-mae:0.199338\n",
      "[912]\tTest-mae:0.19933\n",
      "[913]\tTest-mae:0.199321\n",
      "[914]\tTest-mae:0.199313\n",
      "[915]\tTest-mae:0.199306\n",
      "[916]\tTest-mae:0.199298\n",
      "[917]\tTest-mae:0.199287\n",
      "[918]\tTest-mae:0.199276\n",
      "[919]\tTest-mae:0.199265\n",
      "[920]\tTest-mae:0.199255\n",
      "[921]\tTest-mae:0.199248\n",
      "[922]\tTest-mae:0.19924\n",
      "[923]\tTest-mae:0.199233\n",
      "[924]\tTest-mae:0.199223\n",
      "[925]\tTest-mae:0.199215\n",
      "[926]\tTest-mae:0.199209\n",
      "[927]\tTest-mae:0.1992\n",
      "[928]\tTest-mae:0.19919\n",
      "[929]\tTest-mae:0.199183\n",
      "[930]\tTest-mae:0.199173\n",
      "[931]\tTest-mae:0.199166\n",
      "[932]\tTest-mae:0.199158\n",
      "[933]\tTest-mae:0.199151\n",
      "[934]\tTest-mae:0.199142\n",
      "[935]\tTest-mae:0.199135\n",
      "[936]\tTest-mae:0.199126\n",
      "[937]\tTest-mae:0.199119\n",
      "[938]\tTest-mae:0.199112\n",
      "[939]\tTest-mae:0.199104\n",
      "[940]\tTest-mae:0.199097\n",
      "[941]\tTest-mae:0.199089\n",
      "[942]\tTest-mae:0.199082\n",
      "[943]\tTest-mae:0.199074\n",
      "[944]\tTest-mae:0.199067\n",
      "[945]\tTest-mae:0.199061\n",
      "[946]\tTest-mae:0.199053\n",
      "[947]\tTest-mae:0.199047\n",
      "[948]\tTest-mae:0.19904\n",
      "[949]\tTest-mae:0.199033\n",
      "[950]\tTest-mae:0.199027\n",
      "[951]\tTest-mae:0.19902\n",
      "[952]\tTest-mae:0.199013\n",
      "[953]\tTest-mae:0.199007\n",
      "[954]\tTest-mae:0.198995\n",
      "[955]\tTest-mae:0.198983\n",
      "[956]\tTest-mae:0.198971\n",
      "[957]\tTest-mae:0.198964\n",
      "[958]\tTest-mae:0.198958\n",
      "[959]\tTest-mae:0.198952\n",
      "[960]\tTest-mae:0.198946\n",
      "[961]\tTest-mae:0.19894\n",
      "[962]\tTest-mae:0.198932\n",
      "[963]\tTest-mae:0.198927\n",
      "[964]\tTest-mae:0.198921\n",
      "[965]\tTest-mae:0.198916\n",
      "[966]\tTest-mae:0.198906\n",
      "[967]\tTest-mae:0.1989\n",
      "[968]\tTest-mae:0.19889\n",
      "[969]\tTest-mae:0.198885\n",
      "[970]\tTest-mae:0.198874\n",
      "[971]\tTest-mae:0.198869\n",
      "[972]\tTest-mae:0.198864\n",
      "[973]\tTest-mae:0.198852\n",
      "[974]\tTest-mae:0.198846\n",
      "[975]\tTest-mae:0.198835\n",
      "[976]\tTest-mae:0.19883\n",
      "[977]\tTest-mae:0.198819\n",
      "[978]\tTest-mae:0.198814\n",
      "[979]\tTest-mae:0.198806\n",
      "[980]\tTest-mae:0.198795\n",
      "[981]\tTest-mae:0.19879\n",
      "[982]\tTest-mae:0.198783\n",
      "[983]\tTest-mae:0.198777\n",
      "[984]\tTest-mae:0.19877\n",
      "[985]\tTest-mae:0.198762\n",
      "[986]\tTest-mae:0.198757\n",
      "[987]\tTest-mae:0.198746\n",
      "[988]\tTest-mae:0.198741\n",
      "[989]\tTest-mae:0.198734\n",
      "[990]\tTest-mae:0.198723\n",
      "[991]\tTest-mae:0.198718\n",
      "[992]\tTest-mae:0.198712\n",
      "[993]\tTest-mae:0.198708\n",
      "[994]\tTest-mae:0.198701\n",
      "[995]\tTest-mae:0.198695\n",
      "[996]\tTest-mae:0.19869\n",
      "[997]\tTest-mae:0.198683\n",
      "[998]\tTest-mae:0.198676\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.198676450573943"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"my_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.46673247, 0.2326023 , 0.20840654, ..., 0.20840654, 0.10195741,\n",
       "       0.55320233], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"my_model.model\")\n",
    "# And use it for predictions.\n",
    "loaded_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
